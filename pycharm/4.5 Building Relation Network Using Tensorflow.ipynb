{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Recognition Using Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last tutorial, we saw how to use the siamese networks to recognize a face. Now we will see how to use the siamese networks to recognize the audio. We will train our network to differentiate between a dog's and a cat's sound. The dataset of cats and dogs audio can be downloaded from here https://www.kaggle.com/mmoreaux/audio-cats-and-dogs#cats_dogs.zip\n",
    "\n",
    "Once we have downloaded the data, we fragment our data into three folders Dogs, Sub_dogs, and Cats. In Dogs and Sub_dogs, we place the dog's barking audio and in Cats folder, we place the cat's audio. The objective of our network is to recognize whether the audio is the dog's barking sound or some different sound. As we know for a Siamese network, we need to feed input as a pair, we select an audio from Dogs and Sub_dogs folder and mark it as a genuine pair and we select an audio from Dogs and Cats folder and mark it as an imposite pair. That is, (dogs, subdogs) is genuine pair and (dogs, cats) is imposite pair.\n",
    "\n",
    "Now we will step by step how to train our siamese network to recognize whether the audio is the dog's barking sound or some different sound. First, We will load all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nogag\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "sad imports\n",
      "sad imports\n",
      "sad imports\n",
      "sad imports\n",
      "sad imports\n",
      "sad imports\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[1]:\n",
    "from preprocessing import cv_preprocessing\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "print(\"sad imports\")\n",
    "\n",
    "#basic imports\n",
    "import glob\n",
    "#import IPython\n",
    "from random import randint\n",
    "print(\"sad imports\")\n",
    "\n",
    "#data processing\n",
    "import numpy as np\n",
    "print(\"sad imports\")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, auc, average_precision_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"sad imports\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras import backend as K\n",
    "print(\"sad imports\")\n",
    "\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "print(\"sad imports\")\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from load_data import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_results(y_true, y_pred, name=''):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    avs = average_precision_score(y_true, y_pred)\n",
    "    auc_score = auc(recall, precision)\n",
    "\n",
    "    print('/n/n', name)\n",
    "\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"recall precision curve\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(y_pred)\n",
    "    plt.title(\"prediction histogram\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"pr_auc = {auc_score}\")\n",
    "\n",
    "    print(f\"average_precision_score = {avs}\")\n",
    "\n",
    "    print(f\"holdout i = , roc_auc = {roc_auc_score(y_true, y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load one audio file and see the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_preprocessed, features, target_feature = load_data()\n",
    "df_preprocessed = df_preprocessed.dropna(subset=['target_binary_intrusion'], how='any')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocessed[features], df_preprocessed['target_binary_intrusion'],\n",
    "                                      test_size=0.15, stratify=df_preprocessed['target_binary_intrusion'])\n",
    "X_train, X_test = cv_preprocessing(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 85)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedding_function(x):\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([42,1]))\n",
    "    bias = tf.Variable(tf.truncated_normal([1]))\n",
    "    \n",
    "    a = (tf.nn.xw_plus_b(x,weights,bias))\n",
    "    embeddings = tf.nn.relu(a)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_function(x):\n",
    "    w1 = tf.Variable(tf.truncated_normal([2,3]))\n",
    "    b1 = tf.Variable(tf.truncated_normal([3]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([3,5]))\n",
    "    b2 = tf.Variable(tf.truncated_normal([5]))\n",
    "    \n",
    "    w3 = tf.Variable(tf.truncated_normal([5,1]))\n",
    "    b3 = tf.Variable(tf.truncated_normal([1]))\n",
    "    \n",
    "    #layer1\n",
    "    z1 = (tf.nn.xw_plus_b(x,w1,b1))\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    \n",
    "    #layer2\n",
    "    z2 = tf.nn.xw_plus_b(a1,w2,b2)\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    \n",
    "    #layer3\n",
    "    z3 = tf.nn.xw_plus_b(z2,w3,b3)\n",
    "\n",
    "    #output\n",
    "    y = tf.nn.sigmoid(z3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xi = tf.placeholder(tf.float32, [None, 42])\n",
    "xj = tf.placeholder(tf.float32, [None, 42])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_xi = embedding_function(xi)\n",
    "f_xj = embedding_function(xj)\n",
    "Z = tf.concat([f_xi,f_xj],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = X_train.iloc[:,:42].astype('float32').values\n",
    "d2 = X_train.iloc[:,42:84].astype('float32').values\n",
    "y_train = y_train.values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: loss 0.367 \n",
      "Episode 100: loss 0.141 \n",
      "Episode 200: loss 0.107 \n"
     ]
    }
   ],
   "source": [
    "relation_scores = relation_function(Z)\n",
    "loss_function = tf.reduce_mean(tf.squared_difference(relation_scores,y))\n",
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train = optimizer.minimize(loss_function)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for episode in range(201):\n",
    "    _, loss_value = sess.run([train, loss_function], \n",
    "                             feed_dict={xi:d1 + np.random.randn(*np.shape(d1))*0.05,\n",
    "                                        xj:d2 + np.random.randn(*np.shape(d2))*0.05,\n",
    "                                        y:y_train})\n",
    "    if episode % 100 == 0:\n",
    "        print(\"Episode {}: loss {:.3f} \".format(episode, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [0.4134862],\n",
      "       [1.       ],\n",
      "       [1.       ],\n",
      "       [1.       ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "d1 = X_test.iloc[:,:42].astype('float32').values\n",
    "d2 = X_test.iloc[:,42:84].astype('float32').values\n",
    "\n",
    "feed_dict = {xi:d1,\n",
    "             xj:d2}\n",
    "classification = sess.run([relation_scores], feed_dict)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data for training and testing with 75% training and 25% testing proportions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we set the epoch length to 13 and we use RMS prop for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6eb94daa1f1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(5)\n",
    "\n",
    "for train, test in cv.split(X, Y):\n",
    "    \n",
    "    x_train, y_train = X[train], Y[train]\n",
    "    x_test, y_test = X[test], Y[test]\n",
    "    epochs = 13\n",
    "    rms = RMSprop()\n",
    "\n",
    "    base_network = build_base_network(input_dim)\n",
    "    audio_1 = x_train[:, 0]\n",
    "    audio_2 = x_train[:, 1]\n",
    "    feat_vecs_a = base_network(audio_a)\n",
    "    feat_vecs_b = base_network(audio_b)\n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
    "    model = Model(inputs = [audio_a, audio_b], outputs=distance)\n",
    "    model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "\n",
    "\n",
    "\n",
    "    model.fit([audio_1, audio_2], y_train.astype(float))\n",
    "\n",
    "    print_results(y_test, model.predict([x_test[:,0], x_test[:,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
