{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score, precision_recall_curve, auc, average_precision_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xlsxwriter\n",
    "from random import randint\n",
    "random_state = 7656\n",
    "from preprocessing import stds, stats, cv_preprocessing\n",
    "from load_data import load_data\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "#from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n",
    "\n",
    "for i in range(len(target_feature)):\n",
    "    print ('\\n\\n\\n', target_feature[i], '\\n-------------------')\n",
    "    X, X_out, Y, y_out = train_test_split(df_preprocessed[features], df_preprocessed[target_feature[i]],\\\n",
    "                                          test_size=0.25, random_state=random_state,\\\n",
    "                                          stratify=df_preprocessed[target_feature[i]])\n",
    "\n",
    "\n",
    "\n",
    "    for i in [random_state, random_state-195, random_state+344, random_state-347, random_state+89]:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y,  random_state=i, test_size=0.2, stratify=Y)\n",
    "        cv = StratifiedKFold(6, random_state=i, shuffle=True)\n",
    "\n",
    "        X_train, X_test = cv_preprocessing(X_train, X_test, i)\n",
    "\n",
    "        pipe = Pipeline(steps=[\n",
    "        ('rfe', RFE(ExtraTreesClassifier())),\n",
    "        ('classifier', CatBoostClassifier(verbose=0, random_state=i))])\n",
    "\n",
    "        grid_params = [{\n",
    "        'rfe__n_features_to_select':[50, 100],\n",
    "        'classifier__class_weights':[[200,1]],#, [1, 15], [1, 30]],\n",
    "        'classifier__l2_leaf_reg': [100, 30],# 50],\n",
    "        'classifier__depth': [5],#, 9]\n",
    "        }]\n",
    "        clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n",
    "        clf.fit(X_train, y_train.values.astype(int))#, fit_params = {'classifier__early_stopping_rounds':15})\n",
    "        print(f\"i = {i}, roc_auc = {clf.best_score_}, params = {clf.best_params_}\")\n",
    "        y_pred_target = clf.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test.astype(int), y_pred_target)\n",
    "        avs = average_precision_score(y_test.astype(int), y_pred_target)\n",
    "        print(f\"average_precision_score = {avs}\")\n",
    "\n",
    "        auc_score = auc(recall, precision)\n",
    "        print(f\"pr_auc = {auc_score}\")\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "#         print(f\"holdout i = {i}, roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")\n",
    "#         for i, j in zip(X_train.columns, clf.best_estimator_['rfe'].ranking_):\n",
    "#             if j == 1:\n",
    "#                 print(i)\n",
    "#         print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n",
    "df_preprocessed = df_preprocessed[~df_preprocessed['phq3'].isna()]\n",
    "secondary_targets = ['PCL_Strict3',\n",
    " 'target_avoidance',\n",
    " 'target_hyper', 'phq3']\n",
    "\n",
    "for i in range(len(target_feature)):\n",
    "    print ('\\n\\n\\n', target_feature[i], '\\n-------------------')\n",
    "    X, X_out, Y, y_out = train_test_split(df_preprocessed[features + secondary_targets], df_preprocessed['target_intrusion'] > 8,\\\n",
    "                                          test_size=0.25, random_state=random_state,\\\n",
    "                                          stratify=df_preprocessed['target_intrusion'] > 8)\n",
    "\n",
    "\n",
    "\n",
    "    for i in [random_state, random_state-195, random_state+344, random_state-347, random_state+89]:\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y,  random_state=i, test_size=0.2, stratify=Y)\n",
    "        cv = StratifiedKFold(6, random_state=i, shuffle=True)\n",
    "        \n",
    "        train_targets = x_train[secondary_targets]\n",
    "        test_targets = x_test[secondary_targets]\n",
    "    \n",
    "        x_train = x_train[features]\n",
    "        x_test = x_test[features]\n",
    "    \n",
    "        x_train, x_test = cv_preprocessing(x_train, x_test, i)\n",
    "\n",
    "        \n",
    "\n",
    "        lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state, class_weights=[1,7])\n",
    "        lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "        lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "        lr_phq = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "        lr_ptsd = CatBoostClassifier(verbose=0, random_state=random_state, class_weights=[1,14])\n",
    "\n",
    "\n",
    "        #lr_intrusion.fit(x_train, np.log(train_targets['target_intrusion'] + 1))\n",
    "        lr_avoidnce.fit(x_train, np.log(train_targets['target_avoidance'] + 1))\n",
    "        lr_hyper.fit(x_train, np.log(train_targets['target_hyper'] + 1))\n",
    "        lr_phq.fit(x_train, np.log(train_targets['phq3']+1))\n",
    "        \n",
    "        lr_ptsd.fit(x_train, y_train.astype(int))\n",
    "        lr_intrusion.fit(x_train, (train_targets['PCL_Strict3']).astype(int))\n",
    "\n",
    "\n",
    "#         intrusion = lr_intrusion.predict_proba(x_test)[:,1]\n",
    "#         avoidance = lr_avoidnce.predict_proba(x_test)[:,1]\n",
    "#         hyper = lr_hyper.predict_proba(x_test)[:,1]\n",
    "        \n",
    "        #intrusion = lr_intrusion.predict(x_test)\n",
    "        avoidance = lr_avoidnce.predict(x_test)\n",
    "        hyper = lr_hyper.predict(x_test)\n",
    "        phq = lr_hyper.predict(x_test)\n",
    "        ptsd = lr_ptsd.predict_proba(x_test)[:, 1]\n",
    "        intrusion = lr_intrusion.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    \n",
    "        y_pred_target = (intrusion + ptsd*4)\n",
    "        \n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test.astype(int), y_pred_target)\n",
    "        avs = average_precision_score(y_test.astype(int), y_pred_target)\n",
    "        print(f\"average_precision_score = {avs}\")\n",
    "\n",
    "        auc_score = auc(recall, precision)\n",
    "        print(f\"pr_auc = {auc_score}\")\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "        print(f\"holdout i = {i}, roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")\n",
    "#         for i, j in zip(X_train.columns, clf.best_estimator_['rfe'].ranking_):\n",
    "#             if j == 1:\n",
    "#                 print(i)\n",
    "#         print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        visible = Input(shape=(102,))\n",
    "        #x = Dense(30, activation='relu')(visible)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "\n",
    "        x = Dense(10, activation='relu')(visible)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        outputs = [Dense(1, activation='sigmoid')(x)]\n",
    "        \n",
    "        for i in targets_list:\n",
    "            outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "    \n",
    "\n",
    "        #outputs = [output1, output2, output3, output4, output5, output6,\n",
    "         #          output7, output8, output9, output10, output11,\n",
    "          #         output12, output13, output14, output15, output16,\n",
    "           #        output17, output18, output19, output20, output21,\n",
    "            #       output22, output23, output24, output25, output26]\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=visible, outputs=outputs)\n",
    "        #callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "        model.compile(loss=['binary_crossentropy']+['binary_crossentropy'] * len(targets_list),\n",
    "              optimizer=Adam(), loss_weights = [1] + [1e-1] * len(targets_list))\n",
    "        \n",
    "        model.fit(X_train,y_trains , epochs = 250, verbose=0)\n",
    "        # evaluate the model\n",
    "        y_pred = (model.predict(X[features].iloc[test])[0] > lim).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n",
    "df_preprocessed = df_preprocessed[~df_preprocessed['phq3'].isna()]\n",
    "secondary_targets = {\n",
    "    'PCL_Strict3':1,\n",
    " 'target_avoidance':5,\n",
    " 'target_hyper':7,\n",
    "    'phq3':13\n",
    "}\n",
    "\n",
    "for j in range(len(target_feature)):\n",
    "    X, X_out, Y, y_out = train_test_split(df_preprocessed[features + list(secondary_targets.keys())], df_preprocessed['target_intrusion']>7,\\\n",
    "                                          test_size=0.15, random_state=random_state,\\\n",
    "                                          stratify=df_preprocessed['target_intrusion']>7)\n",
    "\n",
    "\n",
    "\n",
    "    for i in [random_state, random_state-195, random_state+344, random_state-347, random_state+89]:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y,  random_state=i, test_size=0.2, stratify=Y)\n",
    "        cv = StratifiedKFold(6, random_state=i, shuffle=True)\n",
    "        y_train = [y_train]\n",
    "        \n",
    "        for k in secondary_targets.keys():\n",
    "            y_train.append(x_train[k].apply(lambda x: int(x > secondary_targets[k])))\n",
    "        \n",
    "        #y_train[secondary_targets]=x_train[secondary_targets]\n",
    "        x_train = x_train[features]\n",
    "        x_test = x_test[features]\n",
    "    \n",
    "        x_train, x_test = cv_preprocessing(x_train, x_test, i)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        x_train = ss.fit_transform(x_train)\n",
    "        x_test = ss.transform(x_test)\n",
    "        visible = Input(shape=(x_train.shape[1],))\n",
    "   \n",
    "\n",
    "        x = Dense(10, activation='relu')(visible)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        outputs = [Dense(1, activation='sigmoid')(x)]\n",
    "        \n",
    "        \n",
    "        for i in secondary_targets.keys():\n",
    "            outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=visible, outputs=outputs)\n",
    "        #callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "        model.compile(loss=['binary_crossentropy']+['binary_crossentropy'] * len(secondary_targets.keys()),\n",
    "              optimizer=Adam(), loss_weights = [1] + [1e-1] * len(secondary_targets.keys()))\n",
    "        model.fit(x_train,y_train , epochs = 100, class_weight=[{0:1, 1:10}]+[{0:1,1:5}] * len(secondary_targets.keys()), verbose=0)\n",
    "        # evaluate the model\n",
    "        y_pred = model.predict(x_test)[0]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        for t in np.arange(0.1,1,0.1):\n",
    "          #  print(t,'f1_score beta=0.5', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=0.5))\n",
    "           # print(t,'f1_score beta=1', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=1))\n",
    "            #print(t,'f1_score beta=2', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=2))\n",
    "            print(t,'f1_score', f1_score(y_test.astype(int), y_pred>t))\n",
    "\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test.astype(int), y_pred)\n",
    "        avs = average_precision_score(y_test.astype(int), y_pred)\n",
    "        print(f\"average_precision_score = {avs}\")\n",
    "\n",
    "        auc_score = auc(recall, precision)\n",
    "        print(f\"pr_auc = {auc_score}\")\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "        print(f\"holdout i = {i}, roc_auc = {roc_auc_score(y_test.astype(int), y_pred)}\")\n",
    "#         for i, j in zip(X_train.columns, clf.best_estimator_['rfe'].ranking_):\n",
    "#             if j == 1:\n",
    "#                 print(i)\n",
    "#        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n",
    "df_preprocessed = df_preprocessed[~df_preprocessed['phq3'].isna()]\n",
    "secondary_targets = {\n",
    "     'q6.1_INTRU_target':1,\n",
    " 'q6.2_DREAM_target':1,\n",
    " 'q6.3_FLASH_target':1,\n",
    " 'q6.4_UPSET_target':1,\n",
    " 'q6.5_PHYS_target':1,\n",
    " #   'PCL_Strict3':1,\n",
    "# 'target_avoidance':5,\n",
    "# 'target_hyper':7,\n",
    "    #'phq3':13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (df_preprocessed[secondary_targets.keys()] > 1).sum(axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (df_preprocessed[secondary_targets.keys()] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b.count()-b.sum())/b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a.count()-a.sum())/a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n",
    "df_preprocessed = df_preprocessed[~df_preprocessed['phq3'].isna()]\n",
    "secondary_targets = {\n",
    "     'q6.1_INTRU_target':1,\n",
    " 'q6.2_DREAM_target':1,\n",
    " 'q6.3_FLASH_target':1,\n",
    " 'q6.4_UPSET_target':1,\n",
    " 'q6.5_PHYS_target':1,\n",
    " #   'PCL_Strict3':1,\n",
    "# 'target_avoidance':5,\n",
    "# 'target_hyper':7,\n",
    " #   'phq3':13\n",
    "}\n",
    "\n",
    "for j in range(len(target_feature)):\n",
    "    X, X_out, Y, y_out = train_test_split(df_preprocessed[features + list(secondary_targets.keys())], df_preprocessed['target_binary_intrusion'],\\\n",
    "                                          test_size=0.15, random_state=random_state,\\\n",
    "                                          stratify=df_preprocessed['target_binary_intrusion'])\n",
    "\n",
    "\n",
    "\n",
    "    for i in [random_state, random_state-195, random_state+344, random_state-347, random_state+89]:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y,  random_state=i, test_size=0.2, stratify=Y)\n",
    "        cv = StratifiedKFold(6, random_state=i, shuffle=True)\n",
    "        y_train = [y_train]\n",
    "        \n",
    "        for k in secondary_targets.keys():\n",
    "            y_train.append(x_train[k].apply(lambda x: int(x > secondary_targets[k])))\n",
    "        \n",
    "        #y_train[secondary_targets]=x_train[secondary_targets]\n",
    "        x_train = x_train[features]\n",
    "        x_test = x_test[features]\n",
    "    \n",
    "        x_train, x_test = cv_preprocessing(x_train, x_test, i)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        x_train = ss.fit_transform(x_train)\n",
    "        x_test = ss.transform(x_test)\n",
    "        visible = Input(shape=(x_train.shape[1],))\n",
    "   \n",
    "\n",
    "        x = Dense(10, activation='relu')(visible)\n",
    "        x = Dropout(0.1)(x)\n",
    "        \n",
    "        outputs = [Dense(1, activation='sigmoid')(x)]\n",
    "        \n",
    "        \n",
    "        for i in secondary_targets.keys():\n",
    "            outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=visible, outputs=outputs)\n",
    "        #callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "        model.compile(loss=['binary_crossentropy']+['binary_crossentropy'] * len(secondary_targets.keys()),\n",
    "              optimizer=Adam(), loss_weights = [1] + [1e-1] * len(secondary_targets.keys()))\n",
    "        model.fit(x_train,y_train , epochs = 100, class_weight=[{0:1, 1:2}]+[{0:1,1:3}] * len(secondary_targets.keys()), verbose=0)\n",
    "        # evaluate the model\n",
    "        y_pred = model.predict(x_test)[0]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        for t in np.arange(0.1,1,0.1):\n",
    "          #  print(t,'f1_score beta=0.5', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=0.5))\n",
    "           # print(t,'f1_score beta=1', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=1))\n",
    "            #print(t,'f1_score beta=2', precision_recall_fscore_support(y_test.astype(int), y_pred>t, beta=2))\n",
    "            print(t,'f1_score', f1_score(y_test.astype(int), y_pred>t))\n",
    "\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test.astype(int), y_pred)\n",
    "        avs = average_precision_score(y_test.astype(int), y_pred)\n",
    "        print(f\"average_precision_score = {avs}\")\n",
    "\n",
    "        auc_score = auc(recall, precision)\n",
    "        print(f\"pr_auc = {auc_score}\")\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "        print(f\"holdout i = {i}, roc_auc = {roc_auc_score(y_test.astype(int), y_pred)}\")\n",
    "#         for i, j in zip(X_train.columns, clf.best_estimator_['rfe'].ranking_):\n",
    "#             if j == 1:\n",
    "#                 print(i)\n",
    "#        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed, features, target_feature = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
