{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "#from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, make_scorer, f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ops.reset_default_graph()\n",
    "random.seed(271828)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "np.random.seed(271828)\n",
    "#import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "tf.random.set_seed(271828)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCL_calculator(df):\n",
    "\n",
    "    symptomatic_cutoff = 2\n",
    "\n",
    "    intrusion = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH', 'q6.4_UPSET', 'q6.5_PHYS']\n",
    "    avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES', 'q6.9_DISINT', 'q6.10_DTACH',\n",
    "                 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "    tred = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH']\n",
    "    only_avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES']\n",
    "\n",
    "    hypertension = ['q6.13_SLEEP', 'q6.14_ANGER', 'q6.15_CONC', 'q6.16_HYPER', 'q6.17_STRTL']\n",
    "\n",
    "    depression = ['q6.9_DISINT', 'q6.10_DTACH', 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "\n",
    "    df[intrusion + avoidance + hypertension].fillna(df[intrusion + avoidance + hypertension].mean(axis=1))\n",
    "    intrusion_cuoff = 1\n",
    "    avoidance_cuoff = 3\n",
    "    hypertension_cuoff = 2\n",
    "    only_avoidance_cutoff = 1\n",
    "    depression_cutoff = 2\n",
    "    tred_cutoff = 1\n",
    "\n",
    "    df['sum'] = (df[intrusion + avoidance + hypertension]).sum(axis=1)\n",
    "\n",
    "    df['intrusion'] = (df[intrusion] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['intrusion_cutoff'] = (df['intrusion'] >= intrusion_cuoff).astype(int)\n",
    "\n",
    "    df['avoidance'] = (df[avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['avoidance_cutoff'] = (df['avoidance'] >= avoidance_cuoff).astype(int)\n",
    "\n",
    "    df['depression'] = (df[depression] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['depression_cutoff'] = df['depression'] >= depression_cutoff\n",
    "\n",
    "    df['hypertention'] = (df[hypertension] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['hypertention_cutoff'] = (df['hypertention'] >= hypertension_cuoff).astype(int)\n",
    "\n",
    "    df['tred'] = (df[tred] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['tred_cutoff'] = df['tred'] >= tred_cutoff\n",
    "\n",
    "    df['only_avoidance'] = (df[only_avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['only_avoidance_cutoff'] = df['only_avoidance'] >= only_avoidance_cutoff\n",
    "\n",
    "    df['regression_cutoff_33'] = df['sum'] >= 33\n",
    "    df['regression_cutoff_50'] = df['sum'] >= 50\n",
    "    df['diagnosis'] = ((df['hypertention_cutoff']) & (df['avoidance_cutoff']) & (df['intrusion_cutoff']) & (df['sum'] >= 50))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\‏‏PycharmProjects\\PTSD\\Data\\PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "#combine with specifics of answers\n",
    "df_pcl2 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL2.xlsx\")\n",
    "df_pcl1 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL1.xlsx\")\n",
    "df = df.merge(df_pcl1, on=\"ID\", how='outer')\n",
    "df = df.merge(df_pcl2, suffixes=('_pcl1', '_pcl2'), on=\"ID\", how='outer')\n",
    "\n",
    "df_pcl3 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL3.xlsx\")\n",
    "df_pcl3 = PCL_calculator(df_pcl3)\n",
    "df = df.merge(df_pcl3.drop(['PCL3_Strict', 'pcl3', 'PCL3_Broad'], axis=1), on=\"ID\", how='outer')\n",
    "# rmoving missing Y's\n",
    "df = df[~df['PCL_Strict3'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\"age\", \"highschool_diploma\", \"dyslexia\", \"ADHD\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"phq1\", \"lot1\",\n",
    "                \"trait1\",\n",
    "                \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\",\n",
    "                \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\",\n",
    "                \"humor1\",\n",
    "                \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\", \"planning2\",\n",
    "                \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\",\n",
    "                \"instrumental_support2\",\n",
    "                \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\",\n",
    "                \"self_blame2\",\n",
    "                \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", 'q6.1_INTRU_pcl1', \n",
    "                'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                  'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                  'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                  'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                  'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                  'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                  'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                  'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = [\"age\", \"highschool_diploma\", \"dyslexia\", \"ADHD\", \"phq1\", \"lot1\",\n",
    "                    \"trait1\", \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\",\n",
    "                    \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\", \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\",\n",
    "                    \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\", \"religion1\",\n",
    "                    \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                    \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\",\n",
    "                    \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\",\n",
    "                    \"instrumental_support2\", \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\",\n",
    "                    \"behavioral_disengagement2\", \"self_blame2\", \"trauma_history8_1\",\n",
    "                    'q6.1_INTRU_pcl1', 'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                    'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                    'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                    'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                    'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                    'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                    'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                    'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2',\n",
    "                    'intrusion', 'only_avoidance', 'hypertention', 'depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_features = [\"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\"]\n",
    "continuous_features = [\"T1Acc1t\", \"T1Acc1n\", \"T1bias\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[genome_features] = df[genome_features].fillna(0)\n",
    "df[continuous_features] = df[continuous_features].fillna(df[continuous_features].mean())\n",
    "df[discrete_features] = df[discrete_features].fillna(df[discrete_features].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut off the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_out, Y, y_out = train_test_split(df[features + ['intrusion', 'only_avoidance', 'hypertention', 'depression']], df['PCL_Strict3'],\n",
    "                                      test_size=0.25, random_state=271828, stratify=df['PCL_Strict3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=271828)\n",
    "cv = StratifiedKFold(5, random_state=271828)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'depression_cutoff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'depression_cutoff'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-363c2fd59dcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'depression_cutoff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'depression_cutoff'"
     ]
    }
   ],
   "source": [
    "X_train['depression_cutoff'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV model of roc auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1= 5 layer2= 5 epochs= 400 Dropout= 0.75\n",
      "scores_f= [0.33333333333333337, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_p= [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_r= [0.2, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_auc= [0.6, 0.5, 0.5, 0.5, 0.5]\n",
      "mean auc= 0.52\n",
      "layer1= 30 layer2= 5 epochs= 400 Dropout= 0.75\n",
      "scores_f= [0.33333333333333337, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_p= [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_r= [0.2, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_auc= [0.6, 0.5, 0.5, 0.5, 0.5]\n",
      "mean auc= 0.52\n",
      "layer1= 5 layer2= 5 epochs= 400 Dropout= 0.5\n",
      "scores_f= [0.4000000000000001, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_p= [0.4, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_r= [0.4, 0.0, 0.0, 0.0, 0.0]\n",
      "scores_auc= [0.6805194805194805, 0.5, 0.48026315789473684, 0.5, 0.5]\n",
      "mean auc= 0.5321565276828435\n",
      "layer1= 30 layer2= 5 epochs= 400 Dropout= 0.5\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'batch_normalization_v2_38/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'batch_normalization_v2_38/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-671367172880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'intrusion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'only_avoidance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hypertention'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'depression'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_cv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[0mX_train_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'intrusion'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'only_avoidance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hypertention'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'depression'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, callbacks=[EarlyStopping(monitor='val_loss', patience=patience, verbose=0)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;31m# Get step function and loop type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m   \u001b[0muse_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_dataset\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[1;34m(model, mode)\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   2229\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2231\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2232\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_fit_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2175\u001b[0m     ]\n\u001b[0;32m   2176\u001b[0m     self._make_train_function_helper(\n\u001b[1;32m-> 2177\u001b[1;33m         '_fit_function', [self.total_loss] + metrics_tensors)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function_helper\u001b[1;34m(self, fn_name, outputs)\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;31m# Training updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m             updates = self.optimizer.get_updates(\n\u001b[1;32m-> 2149\u001b[1;33m                 params=self._collected_trainable_weights, loss=self.total_loss)\n\u001b[0m\u001b[0;32m   2150\u001b[0m       \u001b[1;31m# Unconditional updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m       \u001b[0mupdates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_updates_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graphs\u001b[1;34m(if_op)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graph_for_branch\u001b[1;34m(branch_name)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, input_shapes)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dr in [0.75, 0.5]:\n",
    "    for epochs in [400]:\n",
    "        for layer2 in [5]:\n",
    "            for layer1 in [5, 30]:\n",
    "                print(\"layer1=\", layer1,\"layer2=\", layer2, \"epochs=\", epochs, \"Dropout=\", dr)\n",
    "                scores_f = []\n",
    "                scores_p = []\n",
    "                scores_r = []\n",
    "                scores_auc = []\n",
    "                for train, test in cv.split(X_train, y_train):\n",
    "                    X_train_cv = X_train.iloc[train]\n",
    "                    y_train_cv = y_train.iloc[train]\n",
    "\n",
    "                    visible = Input(shape=(92,))\n",
    "                    x = Dense(layer1, activation='elu')(visible)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x = Dropout(dr)(x)\n",
    "\n",
    "                    if layer2 > 0:\n",
    "                        x = Dense(layer2, activation='elu')(x)\n",
    "                        x = BatchNormalization()(x)\n",
    "                        x = Dropout(dr)(x)\n",
    "\n",
    "\n",
    "                    output_intrusion = Dense(1)(x)\n",
    "                    output_avoid = Dense(1)(x)\n",
    "                    output_hype = Dense(1)(x)\n",
    "                    output_depression = Dense(1)(x)\n",
    "                    output_diagnosis = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "                    model = Model(inputs=visible, outputs=[output_intrusion, output_avoid, output_hype,output_depression, output_diagnosis])\n",
    "\n",
    "                    model.compile(loss=[\"mean_squared_error\"] * 4 + [\"binary_crossentropy\"],\n",
    "                              optimizer='adam', loss_weights = [0.1] * 4 + [1])\n",
    "                    t = [X_train_cv['intrusion'], X_train_cv['only_avoidance'],X_train_cv['hypertention'], X_train_cv['depression'], y_train_cv]\n",
    "                    X_train_cv.drop(['intrusion', 'only_avoidance', 'hypertention', 'depression'], axis=1, inplace=True)\n",
    "                    model.fit(X_train_cv, t, epochs=epochs, verbose=0, validation_split=0.15)#, callbacks=[EarlyStopping(monitor='val_loss', patience=patience, verbose=0)])\n",
    "                    y_pred = model.predict(X_train[features].iloc[test])[4] >= 0.5\n",
    "\n",
    "                    scores_f.append(f1_score(y_train.iloc[test], y_pred))\n",
    "                    scores_p.append(precision_score(y_train.iloc[test], y_pred))\n",
    "                    scores_r.append(recall_score(y_train.iloc[test], y_pred))\n",
    "                    scores_auc.append(roc_auc_score(y_train.iloc[test], y_pred))\n",
    "                ### results\n",
    "                print(\"scores_f=\",scores_f)\n",
    "                print(\"scores_p=\",scores_p)\n",
    "                print(\"scores_r=\",scores_r)\n",
    "                print(\"scores_auc=\",scores_auc)\n",
    "                print(\"mean auc=\",np.mean(scores_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(t[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_f)\n",
    "print(scores_p)\n",
    "print(scores_r)\n",
    "print(scores_auc)\n",
    "print(np.mean(scores_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_15 to have shape (92,) but got array with shape (96,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-202789beb2ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#X_test.drop(['intrusion_cutoff', 'avoidance_cutoff', 'hypertention_cutoff'], axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;31m# generate symbolic tensors).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1149\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2594\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2596\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow-2.0.0a0-py3.6-win-amd64.egg\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    347\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    350\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_15 to have shape (92,) but got array with shape (96,)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "#X_test.drop(['intrusion_cutoff', 'avoidance_cutoff', 'hypertention_cutoff'], axis=1, inplace=True)\n",
    "probs = model.predict(X_test)[3]\n",
    "preds = probs\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(preds[y_test==0], bins=50, color=\"b\")\n",
    "plt.hist(preds[y_test==1], bins=20, alpha=0.8, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
