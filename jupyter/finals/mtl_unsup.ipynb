{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "#from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "ops.reset_default_graph()\n",
    "random.seed(271828)\n",
    "np.random.seed(271828)\n",
    "#import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "tf.random.set_seed(271828)\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.cluster import KMeans,DBSCAN, MeanShift\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multitask-learning-teach-your-ai-more-to-make-it-better-dde116c2cd40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = {\n",
    "    'q6.1_INTRU': 1,\n",
    "    'q6.2_DREAM': 1,\n",
    "    'q6.3_FLASH': 1,\n",
    "    'q6.4_UPSET': 0,\n",
    "    'q6.5_PHYS': 0,\n",
    "    'q6.6_AVTHT': 0,\n",
    "    'q6.7_AVSIT': 0,\n",
    "    'q6.8_AMNES': 0,\n",
    "    'q6.9_DISINT': 0,\n",
    "    'q6.10_DTACH': 0,\n",
    "    'q6.11_NUMB': 0,\n",
    "    'q6.12_FUTRE': 0,\n",
    "    'q6.13_SLEEP': 0,\n",
    "    'q6.14_ANGER': 0,\n",
    "    'q6.15_CONC': 0,\n",
    "    'q6.16_HYPER': 0,\n",
    "    'q6.17_STRTL': 0,\n",
    "    'intrusion_cutoff': 0,\n",
    "    'avoidance_cutoff': 0,\n",
    "    'hypertention_cutoff': 0,\n",
    "    'depression_cutoff':0,\n",
    "    'only_avoidance_cutoff': 0,\n",
    "    'regression_cutoff_33': 0,\n",
    "    'regression_cutoff_50': 0,\n",
    "    'tred_cutoff': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH', 'q6.4_UPSET', 'q6.5_PHYS',\n",
    "                 'q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES', 'q6.9_DISINT', 'q6.10_DTACH',\n",
    "                 'q6.11_NUMB', 'q6.12_FUTRE', 'q6.13_SLEEP', 'q6.14_ANGER', 'q6.15_CONC',\n",
    "                 'q6.16_HYPER', 'q6.17_STRTL']\n",
    "targets_list = [i for i in targets_dict if targets_dict[i] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCL_calculator(df):\n",
    "\n",
    "    symptomatic_cutoff = 2\n",
    "\n",
    "    intrusion = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH', 'q6.4_UPSET', 'q6.5_PHYS']\n",
    "    avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES', 'q6.9_DISINT', 'q6.10_DTACH',\n",
    "                 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "    tred = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH']\n",
    "    only_avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES']\n",
    "\n",
    "    hypertension = ['q6.13_SLEEP', 'q6.14_ANGER', 'q6.15_CONC', 'q6.16_HYPER', 'q6.17_STRTL']\n",
    "\n",
    "    depression = ['q6.9_DISINT', 'q6.10_DTACH', 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "\n",
    "    df[intrusion + avoidance + hypertension].fillna(df[intrusion + avoidance + hypertension].mean(axis=1))\n",
    "    intrusion_cuoff = 1\n",
    "    avoidance_cuoff = 3\n",
    "    hypertension_cuoff = 2\n",
    "    only_avoidance_cutoff = 1\n",
    "    depression_cutoff = 2\n",
    "    tred_cutoff = 1\n",
    "\n",
    "    df['sum'] = (df[intrusion + avoidance + hypertension]).sum(axis=1)\n",
    "\n",
    "    df['intrusion'] = (df[intrusion] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['intrusion_cutoff'] = df['intrusion'] >= intrusion_cuoff\n",
    "\n",
    "    df['avoidance'] = (df[avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['avoidance_cutoff'] = df['avoidance'] >= avoidance_cuoff\n",
    "\n",
    "    df['depression'] = (df[depression] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['depression_cutoff'] = df['depression'] >= depression_cutoff\n",
    "\n",
    "    df['hypertention'] = (df[hypertension] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['hypertention_cutoff'] = df['hypertention'] >= hypertension_cuoff\n",
    "\n",
    "    df['tred'] = (df[tred] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['tred_cutoff'] = df['tred'] >= tred_cutoff\n",
    "\n",
    "    df['only_avoidance'] = (df[only_avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['only_avoidance_cutoff'] = df['only_avoidance'] >= only_avoidance_cutoff\n",
    "\n",
    "    df['regression_cutoff_33'] = df['sum'] >= 33\n",
    "    df['regression_cutoff_50'] = df['sum'] >= 50\n",
    "    df['diagnosis'] = ((df['hypertention_cutoff']) & (df['avoidance_cutoff']) & (df['intrusion_cutoff']) & (df['sum'] >= 50))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PTSD_Model:\n",
    "\n",
    "    features = [\"age\", \"highschool_diploma\", \"dyslexia\", \"ADHD\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", \"phq1\", \"lot1\",\n",
    "                \"trait1\",\n",
    "                \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\",\n",
    "                \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\",\n",
    "                \"humor1\",\n",
    "                \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\", \"planning2\",\n",
    "                \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\",\n",
    "                \"instrumental_support2\",\n",
    "                \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\",\n",
    "                \"self_blame2\",\n",
    "                \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\"]\n",
    "\n",
    "    features_2 = ['q6.1_INTRU_pcl1', 'q6.2_DREAM_pcl1',\n",
    "                  'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                  'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                  'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                  'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                  'intrusion_pcl1', 'avoidance_pcl1', 'hypertention_pcl1', 'depression_pcl1', 'tred_pcl1',\n",
    "                  'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2',\n",
    "                  'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                  'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                  'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                  'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2',\n",
    "                  'intrusion_pcl2', 'avoidance_pcl2', 'hypertention_pcl2', 'depression_pcl2', 'tred_pcl2']\n",
    "    target_features = [\"PCL_Strict3\", \"PCL3\"]\n",
    "    target_features_2 = [\"intrusion_cutoff\", \"avoidance_cutoff\", \"hypertention_cutoff\",\n",
    "                         'depression_cutoff', 'diagnosis', \"PCL3\", \"only_avoidance_cutoff\", \"tred_cutoff\",\n",
    "                         \"regression_cutoff_33\", \"regression_cutoff_50\"]\n",
    "    ID = [\"ID\"]\n",
    "    dataset_path = r\"../Data/PTSD.xlsx\"\n",
    "\n",
    "    multiple_features_no_imputation = ['q6.16_HYPER_pcl1',  'hypertention_pcl2', 'q6.5_PHYS_pcl2', 'q6.12_FUTRE_pcl1',\n",
    "                                       'cd_risc1',  'q6.2_DREAM_pcl2',  'q6.14_ANGER_pcl2', 'positive_reframing2',\n",
    "                                       'venting2', 'q6.15_CONC_pcl1', 'q6.8_AMNES_pcl1',\n",
    "                                       'q6.15_CONC_pcl2', 'PCL_Broad2', 'phq2', 'q6.4_UPSET_pcl2']\n",
    "\n",
    "    def __init__(self):\n",
    "        path = \"C:\\‏‏PycharmProjects\\PTSD\\Data\\PTSD.xlsx\"\n",
    "        df = pd.read_excel(path)\n",
    "        df = df[~df['PCL_Strict3'].isna()]\n",
    "        #df = df[~ ((df[\"military_exp18_t3\"] == 0) & (df[\"military_exp18_t2\"] == 0))]\n",
    "        df = df[self.features + self.ID + self.target_features]\n",
    "        df_pcl3 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL3.xlsx\")\n",
    "        df_pcl3 = PCL_calculator(df_pcl3)\n",
    "        df_pcl2 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL2.xlsx\")\n",
    "        df_pcl2 = PCL_calculator(df_pcl2)\n",
    "        df_pcl1 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL1.xlsx\")\n",
    "        df_pcl1 = PCL_calculator(df_pcl1)\n",
    "\n",
    "        df = df.merge(df_pcl1, on=\"ID\", how='outer')\n",
    "        df = df.merge(df_pcl2, suffixes=('_pcl1', '_pcl2'), on=\"ID\", how='outer')\n",
    "        df = df.merge(df_pcl3.drop(['PCL3_Strict', 'pcl3', 'PCL3_Broad'], axis=1), on=\"ID\", how='outer')\n",
    "\n",
    "        df = df[~df['PCL_Strict3'].isna()]\n",
    "        #df = df[~df['tred_cutoff'].isna()]\n",
    "        df.drop(self.ID, inplace=True, axis=1)\n",
    "        mice = IterativeImputer()\n",
    "        df = pd.DataFrame(mice.fit_transform(df), columns=df.columns)\n",
    "\n",
    "        all_x_col = self.features + self.features_2 + self.target_features_2 + questions\n",
    "        #all_x_col = self.features + self.features_2\n",
    "        #y_col = [\"tred_cutoff\"]\n",
    "        y_col = [\"PCL_Strict3\"]\n",
    "        X = df[all_x_col]\n",
    "        Y = df[y_col]\n",
    "        X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X, Y, test_size=0.25, random_state=271828, stratify=Y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train_0, y_train_0, test_size=0.25, random_state=271828, stratify=y_train_0)\n",
    "        df = pd.concat([X_train, y_train], axis=1)\n",
    "        self.X_test = X_test\n",
    "        self.y_test =y_test\n",
    "\n",
    "        self.X_train_0 = X_train_0\n",
    "        self.X_test_0 = X_test_0\n",
    "        self.y_train_0 = y_train_0\n",
    "        self.y_test_0 = y_test_0\n",
    "\n",
    "        self.df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PTSD_Model()\n",
    "X = m.df.drop(\"PCL_Strict3\", axis=1)\n",
    "Y01 = m.df[\"PCL_Strict3\"].apply(lambda x: int(x))\n",
    "\n",
    "features = m.features + m.features_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SRP = SparseRandomProjection(n_components=154,density = 'auto', eps = 0.5, random_state=2019, dense_output = False)\n",
    "X_srp = SRP.fit_transform(X[features])\n",
    "\n",
    "\n",
    "km = DBSCAN(eps=9, min_samples=100)#n_clusters=4)\n",
    "km = km.fit(X[features])\n",
    "one_0 = X_srp[:, 0][(km.labels_==0)]\n",
    "one_1 = X_srp[:, 1][(km.labels_==0)]\n",
    "#one_2 = s[:, 2][(km.labels_==0)]\n",
    "plt.scatter(one_0, one_1,  c='r')\n",
    "#ax.scatter(one_0, one_1, one_2,  c='r')\n",
    "\n",
    "one_0 = X_srp[:, 0][(km.labels_==1)]\n",
    "one_1 = X_srp[:, 1][(km.labels_==1)]\n",
    "#one_2 = s[:, 2][(km.labels_==1)]\n",
    "\n",
    "plt.scatter(one_0, one_1,  c='b')\n",
    "#ax.scatter(one_0, one_1, one_2, c='c')\n",
    "\n",
    "one_0 = X_srp[:, 0][(km.labels_==2)]\n",
    "one_1 = X_srp[:, 1][(km.labels_==2)]\n",
    "#one_2 = s[:, 2][(km.labels_==2)]\n",
    "\n",
    "plt.scatter(one_0, one_1,  c='y')\n",
    "#ax.scatter(one_0, one_1, one_2, c='y')\n",
    "\n",
    "one_0 = X_srp[:, 0][(km.labels_==-1)]\n",
    "one_1 = X_srp[:, 1][(km.labels_==-1)]\n",
    "#one_2 = s[:, 2][(km.labels_==3)]\n",
    "\n",
    "plt.scatter(one_0, one_1,  c='k')\n",
    "#ax.scatter(one_0, one_1, one_2, c='g')\n",
    "X[\"new\"] = km.labels_\n",
    "features.append(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________ Limit = 0.5 ______________\n",
      "sum(Y1.iloc[test]) = 5\n",
      "sum(y_pred)=[42]\n",
      "\tscores f1 0.21276595744680848\n",
      "\tscores p 0.11904761904761904\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 9\n",
      "sum(y_pred)=[42]\n",
      "\tscores f1 0.35294117647058826\n",
      "\tscores p 0.21428571428571427\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 6\n",
      "sum(y_pred)=[41]\n",
      "\tscores f1 0.2553191489361702\n",
      "\tscores p 0.14634146341463414\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 14\n",
      "sum(y_pred)=[41]\n",
      "\tscores f1 0.5090909090909091\n",
      "\tscores p 0.34146341463414637\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 10\n",
      "sum(y_pred)=[41]\n",
      "\tscores f1 0.39215686274509803\n",
      "\tscores p 0.24390243902439024\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.33333333333333337\n",
      "\tscores p 0.2\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 6\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.2608695652173913\n",
      "\tscores p 0.15\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 4\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.18181818181818182\n",
      "\tscores p 0.1\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.33333333333333337\n",
      "\tscores p 0.2\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.33333333333333337\n",
      "\tscores p 0.2\n",
      "\tscores r 1.0\n",
      "mean scores f1 0.31649618017251474\n",
      "mean scores p 0.19150406504065037\n",
      "mean scores r 1.0\n",
      "____________ Limit = 0.75 ______________\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[42]\n",
      "\tscores f1 0.32\n",
      "\tscores p 0.19047619047619047\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 6\n",
      "sum(y_pred)=[42]\n",
      "\tscores f1 0.25\n",
      "\tscores p 0.14285714285714285\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 9\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.36734693877551017\n",
      "\tscores p 0.225\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 12\n",
      "sum(y_pred)=[41]\n",
      "\tscores f1 0.45283018867924524\n",
      "\tscores p 0.2926829268292683\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 7\n",
      "sum(y_pred)=[41]\n",
      "\tscores f1 0.2916666666666667\n",
      "\tscores p 0.17073170731707318\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.33333333333333337\n",
      "\tscores p 0.2\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 8\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.33333333333333337\n",
      "\tscores p 0.2\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 6\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.2608695652173913\n",
      "\tscores p 0.15\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 7\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.2978723404255319\n",
      "\tscores p 0.175\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 7\n",
      "sum(y_pred)=[40]\n",
      "\tscores f1 0.2978723404255319\n",
      "\tscores p 0.175\n",
      "\tscores r 1.0\n",
      "mean scores f1 0.32051247068565447\n",
      "mean scores p 0.1921747967479675\n",
      "mean scores r 1.0\n"
     ]
    }
   ],
   "source": [
    "for lim in [0.5, 0.75]:\n",
    "    print(f\"____________ Limit = {lim} ______________\")\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    train_scores_f = []\n",
    "    train_scores_p = []\n",
    "    train_scores_r = []\n",
    "\n",
    "    scores_f = []\n",
    "    scores_p = []\n",
    "    scores_r = []\n",
    "    for train, test in kfold.split(X, Y01):\n",
    "        \n",
    "        Y1 = X['tred_cutoff'].apply(lambda x: int(x > 0))\n",
    "        X_train = X.iloc[train]\n",
    "        y_train_1 = X_train['tred_cutoff'].apply(lambda x: int(x > 0))\n",
    "        sm = SMOTE(random_state=27)\n",
    "        cols = X_train.columns\n",
    "        X_train, y_train_1 = sm.fit_sample(X_train, y_train_1.ravel())\n",
    "        X_train = pd.DataFrame(X_train, columns=cols)\n",
    "        y_trains = []\n",
    "        for i in targets_list:\n",
    "            y_trains.append(X_train[i].apply(lambda x: int(x > 0)))\n",
    "        y_trains.append(y_train_1)\n",
    "\n",
    "        X_train = X_train[features]\n",
    "\n",
    "        visible = Input(shape=(103,))\n",
    "        #x = Dense(30, activation='relu')(visible)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "\n",
    "        #x = Dense(20, activation='relu')(visible)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "        x = Dense(20, activation='relu')(visible)\n",
    "        x = Dropout(0.25)(x)\n",
    "        outputs = []\n",
    "        \n",
    "        for i in targets_list:\n",
    "            outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "        x = Dense(10, activation='relu')(visible)\n",
    "        x = Dropout(0.25)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "        outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "        #outputs = [output1, output2, output3, output4, output5, output6,\n",
    "         #          output7, output8, output9, output10, output11,\n",
    "          #         output12, output13, output14, output15, output16,\n",
    "           #        output17, output18, output19, output20, output21,\n",
    "            #       output22, output23, output24, output25, output26]\n",
    "        \n",
    "        \n",
    "        model = Model(inputs=visible, outputs=outputs)\n",
    "        #callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "        model.compile(loss=['binary_crossentropy']+['binary_crossentropy'] * len(targets_list),\n",
    "              optimizer=Adam(), loss_weights =  ([1e-1] * len(targets_list)) + [1])\n",
    "        \n",
    "        model.fit(X_train,y_trains , epochs = 200, verbose=0,\n",
    "                 #class_weight= [{1:10, 0:1}, 2{1:2, 0:1}, {1:2, 0:1}, {1:2, 0:1}]\n",
    "                 )\n",
    "        # evaluate the model\n",
    "        y_pred = (model.predict(X[features].iloc[test])[0] > lim).astype(int)\n",
    "\n",
    "        s_f = f1_score(Y1.iloc[test], y_pred)\n",
    "        s_p = precision_score(Y1.iloc[test], y_pred)\n",
    "        s_r = recall_score(Y1.iloc[test], y_pred)\n",
    "        print(f\"sum(Y1.iloc[test]) = {sum(Y1.iloc[test])}\\nsum(y_pred)={sum(y_pred)}\")\n",
    "        print(\"\\tscores f1\", (s_f))\n",
    "        print(\"\\tscores p\", (s_p))\n",
    "        print(\"\\tscores r\", (s_r))\n",
    "        scores_f.append(s_f)\n",
    "        scores_p.append(s_p)\n",
    "        scores_r.append(s_r)\n",
    "\n",
    "    print(\"mean scores f1\", np.mean(scores_f))\n",
    "    print(\"mean scores p\", np.mean(scores_p))\n",
    "    print(\"mean scores r\", np.mean(scores_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________ Limit = 0.25 ______________\n",
      "sum(Y1.iloc[test]) = 9\n",
      "sum(y_pred)=[15]\n",
      "\tscores f1 0.5\n",
      "\tscores p 0.4\n",
      "\tscores r 0.6666666666666666\n",
      "sum(Y1.iloc[test]) = 6\n",
      "sum(y_pred)=[42]\n",
      "\tscores f1 0.25\n",
      "\tscores p 0.14285714285714285\n",
      "\tscores r 1.0\n",
      "sum(Y1.iloc[test]) = 11\n",
      "sum(y_pred)=[12]\n",
      "\tscores f1 0.34782608695652173\n",
      "\tscores p 0.3333333333333333\n",
      "\tscores r 0.36363636363636365\n",
      "sum(Y1.iloc[test]) = 12\n",
      "sum(y_pred)=[10]\n",
      "\tscores f1 0.45454545454545453\n",
      "\tscores p 0.5\n",
      "\tscores r 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "for lim in [0.25, 0.5, 0.75]:\n",
    "    print(f\"____________ Limit = {lim} ______________\")\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    train_scores_f = []\n",
    "    train_scores_p = []\n",
    "    train_scores_r = []\n",
    "\n",
    "    scores_f = []\n",
    "    scores_p = []\n",
    "    scores_r = []\n",
    "    for train, test in kfold.split(X, Y01):\n",
    "        \n",
    "        Y1 = X['tred_cutoff'].apply(lambda x: int(x > 0))\n",
    "        X_train = X.iloc[train]\n",
    "        y_train_1 = X_train['tred_cutoff'].apply(lambda x: int(x > 0))\n",
    "        sm = SMOTE(random_state=27)\n",
    "        cols = X_train.columns\n",
    "        X_train, y_train_1 = sm.fit_sample(X_train, y_train_1.ravel())\n",
    "        X_train = pd.DataFrame(X_train, columns=cols)\n",
    "        y_trains = [y_train_1]\n",
    "        for i in targets_list:\n",
    "            y_trains.append(X_train[i].apply(lambda x: int(x > 2)))\n",
    "        \n",
    "        X_train = X_train[features]\n",
    "\n",
    "        visible = Input(shape=(103,))\n",
    "        x = Dense(30, activation='relu')(visible)\n",
    "        x = Dropout(0.25)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "\n",
    "        x = Dense(10, activation='relu')(visible)\n",
    "        x = Dropout(0.25)(x)\n",
    "        #x = Dropout(0.1)(x)\n",
    "        #x = Dense(10, activation='relu')(visible)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        outputs = [Dense(1, activation='sigmoid')(x)]\n",
    "        \n",
    "        for i in targets_list:\n",
    "            outputs.append(Dense(1, activation='sigmoid')(x))\n",
    "        \n",
    "        model = Model(inputs=visible, outputs=outputs)\n",
    "        #callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "        model.compile(loss=['binary_crossentropy']+['binary_crossentropy'] * len(targets_list),\n",
    "              optimizer=Adam(), loss_weights =  ([1] + [1e-1] * len(targets_list)))\n",
    "        \n",
    "        model.fit(X_train,y_trains , epochs = 200, verbose=0,\n",
    "                 #class_weight= [{1:10, 0:1}, {1:2, 0:1}, {1:2, 0:1}, {1:2, 0:1}]\n",
    "                 )\n",
    "        # evaluate the model\n",
    "        y_pred = (model.predict(X[features].iloc[test])[0] > lim).astype(int)\n",
    "\n",
    "        s_f = f1_score(Y1.iloc[test], y_pred)\n",
    "        s_p = precision_score(Y1.iloc[test], y_pred)\n",
    "        s_r = recall_score(Y1.iloc[test], y_pred)\n",
    "        print(f\"sum(Y1.iloc[test]) = {sum(Y1.iloc[test])}\\nsum(y_pred)={sum(y_pred)}\")\n",
    "        print(\"\\tscores f1\", (s_f))\n",
    "        print(\"\\tscores p\", (s_p))\n",
    "        print(\"\\tscores r\", (s_r))\n",
    "        scores_f.append(s_f)\n",
    "        scores_p.append(s_p)\n",
    "        scores_r.append(s_r)\n",
    "\n",
    "    print(\"mean scores f1\", np.mean(scores_f))\n",
    "    print(\"mean scores p\", np.mean(scores_p))\n",
    "    print(\"mean scores r\", np.mean(scores_r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 130)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2369001750257061"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X['tred_cutoff']) / (len(X['tred_cutoff']) - sum(X['tred_cutoff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
