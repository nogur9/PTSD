{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_state = 854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "humanitarian-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103, 179)\n",
      "(1103, 179)\n"
     ]
    }
   ],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n",
    "\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009 = df_2009.drop_duplicates(subset=\"ID\")\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009['control'] = np.ones_like(df_2009.ID)\n",
    "df_2009['placebo'] = np.zeros_like(df_2009.ID)\n",
    "df_2009['train_4'] = np.zeros_like(df_2009.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 105)\n"
     ]
    }
   ],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "#df_2016 = df_2016[(df_2016['Wave']=='august12')]\n",
    "\n",
    "\n",
    "df_2016 =df_2016.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2016.shape)\n",
    "df_2016 = pd.concat((df_2016,pd.get_dummies(df_2016.Group)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicare",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sustainable-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "    'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    "  'Accuracy_threat_T1': 'T1Acc1t',\n",
    "  'Accuracy_NT_T1': 'T1Acc1n',\n",
    "  'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " 'Trait_T1': 'trait1',\n",
    " 'State_T1': 'state1',\n",
    " 'PCL_T1': 'PCL1',\n",
    " 'Intrusion_T1':'Intrusion_T1',\n",
    "    'Avoidance_T1': 'Avoidance_T1',\n",
    "    'Hyper_T1': 'Hyper_T1',\n",
    "    'control': 'control',\n",
    "    'placebo': 'placebo',\n",
    "    'train_4': 'train_4'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-diary",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "artificial-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009_1 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "avoidance_features_2009 = [\"q6.6_AVTHT\", \"q6.7_AVSIT\", \"q6.8_AMNES\", \"q6.9_DISINT\", \"q6.10_DTACH\",\n",
    "             \"q6.11_NUMB\", \"q6.12_FUTRE\"]\n",
    "hyper_features_2009 = [\"q6.13_SLEEP\", \"q6.14_ANGER\", \"q6.15_CONC\", \"q6.16_HYPER\", \"q6.17_STRTL\"]\n",
    "\n",
    "\n",
    "df_2009_1 = df_2009.merge(PCL_2009_1[intrusion_features_2009 +avoidance_features_2009+hyper_features_2009+ [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2009['Intrusion_T1'] = df_2009_1[intrusion_features_2009].sum(axis=1)\n",
    "df_2009['Avoidance_T1'] = df_2009_1[avoidance_features_2009].sum(axis=1)\n",
    "df_2009['Hyper_T1'] = df_2009_1[hyper_features_2009].sum(axis=1)\n",
    "\n",
    "trans_2016_2009_features['Intrusion_T1']= 'Intrusion_T1'\n",
    "trans_2016_2009_features['Avoidance_T1']= 'Avoidance_T1'\n",
    "trans_2016_2009_features['Hyper_T1']= 'Hyper_T1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "monetary-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009_3 = pd.read_excel(os.path.join(data_path_2009, \"questionnaire6PCL3.xlsx\"))\n",
    "\n",
    "\n",
    "\n",
    "PCL_2009_3 = df_2009.merge(PCL_2009_3[intrusion_features_2009 +avoidance_features_2009+hyper_features_2009+ [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2009['Intrusion_T4'] = PCL_2009_3[intrusion_features_2009].sum(axis=1)\n",
    "df_2009['Avoidance_T4'] = PCL_2009_3[avoidance_features_2009].sum(axis=1)\n",
    "df_2009['Hyper_T4'] = PCL_2009_3[hyper_features_2009].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'target_feature'\n",
    "secondary_targets = ['Intrusion_T4', 'Avoidance_T4', 'Hyper_T4']\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n",
    "\n",
    "df_2016['target_feature'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "df_2009['target_feature'] = (df_2009['PCL3'] > 39).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-solomon",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 110)\n",
      "(1103, 189)\n"
     ]
    }
   ],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)\n",
    "print(df_2016.shape)\n",
    "print(df_2009.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2016 = df_2016[~df_2016['Intrusion_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Avoidance_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Hyper_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['PCL_T4'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "empty-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009['Intrusion_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['Avoidance_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['Hyper_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['PCL3'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "regulated-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 110)\n",
      "(725, 189)\n"
     ]
    }
   ],
   "source": [
    "print(df_2016.shape)\n",
    "print(df_2009.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sufficient-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(5, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2012, y_2012 = df_2016[(df_2016['Wave']=='august12')][X_features+ secondary_targets], df_2016[(df_2016['Wave']=='august12')][target_feature]\n",
    "\n",
    "x_2009, y_2009 = df_2009[X_features+ secondary_targets], df_2009[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "patient-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2013, y_2013 = df_2016[df_2016['Wave']=='august13'][X_features+ secondary_targets], df_2016[df_2016['Wave']=='august13'][target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "everyday-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2009_2012 = pd.DataFrame(np.vstack([x_2009, x_2012]), columns=X_features+ secondary_targets)\n",
    "Y_2009_2012 = pd.DataFrame(np.hstack([y_2009, y_2012]), columns = [target_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "understood-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6801829268292683\n",
      "roc_auc = 0.8129573170731708\n",
      "roc_auc = 0.650834403080873\n",
      "roc_auc = 0.8260590500641849\n",
      "roc_auc = 0.7164634146341463\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(X_2009_2012, Y_2009_2012):\n",
    "    x_train, y_train = X_2009_2012.iloc[train], Y_2009_2012.iloc[train]\n",
    "    x_test, y_test = X_2009_2012.iloc[test], Y_2009_2012.iloc[test]\n",
    "    train_targets = x_train[secondary_targets]\n",
    "    test_targets = x_test[secondary_targets]\n",
    "    \n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "    \n",
    "    lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "    \n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "\n",
    "    lr_intrusion.fit(x_train, train_targets['Intrusion_T4'].astype(float))\n",
    "    lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'].astype(float))\n",
    "    lr_hyper.fit(x_train, train_targets['Hyper_T4'].astype(float))\n",
    "\n",
    "    \n",
    "    intrusion_train = lr_intrusion.predict(x_train)\n",
    "    avoidance_train = lr_avoidnce.predict(x_train)\n",
    "    hyper_train = lr_hyper.predict(x_train)\n",
    "\n",
    "    intrusion = lr_intrusion.predict(x_test)\n",
    "    avoidance = lr_avoidnce.predict(x_test)\n",
    "    hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "    \n",
    "    y_pred_target = (intrusion + avoidance + hyper ) / 70\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "biblical-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6722077922077923\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = X_2009_2012, Y_2009_2012\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "train_targets = x_train[secondary_targets]\n",
    "test_targets = x_test[secondary_targets]\n",
    "    \n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, train_targets['Intrusion_T4'].astype(float))\n",
    "lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'].astype(float))\n",
    "lr_hyper.fit(x_train, train_targets['Hyper_T4'].astype(float))\n",
    "\n",
    "    \n",
    "intrusion_train = lr_intrusion.predict(x_train)\n",
    "avoidance_train = lr_avoidnce.predict(x_train)\n",
    "hyper_train = lr_hyper.predict(x_train)\n",
    "    \n",
    "    \n",
    "intrusion = lr_intrusion.predict(x_test)\n",
    "avoidance = lr_avoidnce.predict(x_test)\n",
    "hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "y_pred_target = (intrusion + avoidance + hyper) / 70\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-tulsa",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "molecular-pasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6972560975609756\n",
      "roc_auc = 0.8382621951219513\n",
      "roc_auc = 0.6774711168164314\n",
      "roc_auc = 0.8193196405648268\n",
      "roc_auc = 0.6577342747111682\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(X_2009_2012, Y_2009_2012):\n",
    "    x_train, y_train = X_2009_2012.iloc[train], Y_2009_2012.iloc[train]\n",
    "    x_test, y_test = X_2009_2012.iloc[test], Y_2009_2012.iloc[test]\n",
    "    \n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "    \n",
    "    lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "    \n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "\n",
    "    lr_intrusion.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "    y_pred_target = lr_intrusion.predict_proba(x_test)\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "diagnostic-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.5948051948051948\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = X_2009_2012, Y_2009_2012\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "y_pred_target = lr_intrusion.predict_proba(x_test)\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-basement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
