{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 3601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "essential-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103, 179)\n",
      "(1103, 179)\n"
     ]
    }
   ],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n",
    "\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009 =df_2009.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009['control'] = np.ones_like(df_2009.ID)\n",
    "df_2009['placebo'] = np.zeros_like(df_2009.ID)\n",
    "df_2009['train_4'] = np.zeros_like(df_2009.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 105)\n"
     ]
    }
   ],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "df_2016 = df_2016[(df_2016['Wave']=='august12')]\n",
    "\n",
    "\n",
    "df_2016 =df_2016.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2016.shape)\n",
    "df_2016 = pd.concat((df_2016,pd.get_dummies(df_2016.Group)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicare",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustainable-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "    'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    " 'Accuracy_threat_T1': 'T1Acc1t',\n",
    " 'Accuracy_NT_T1': 'T1Acc1n',\n",
    " 'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " 'Trait_T1': 'trait1',\n",
    " 'State_T1': 'state1',\n",
    " 'PCL_T1': 'PCL1',\n",
    "'control':'control',\n",
    "    'placebo': 'placebo',\n",
    "    'train_4': 'train_4'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-diary",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "willing-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_excel(os.path.join(data_path_2009, \"questionnaire6PCL3.xlsx\"))\n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "df_2009_4 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustainable-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "PCL_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire5_PCL.csv\"))                      \n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "intrusion_features_2016 = [\"q5.1\", \"q5.2\", \"q5.3\", \"q5.4\", \"q5.5\"]\n",
    "df_2009 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PCL_2016[intrusion_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(intrusion_features_2009, intrusion_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "about-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire5_PHQ9.csv\"))\n",
    "PHQ9_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire4_PHQ9.csv\"))                      \n",
    "\n",
    "PHQ9_features_2009 = [\"T1q5.1\", \"T1q5.2\", \"T1q5.3\", \"T1q5.4\", \"T1q5.5\", \"T1q5.6\", \"T1q5.7\", \"T1q5.8\", \"T1q5.9\"]\n",
    "PHQ9_features_2016 = [\"q4.1\", \"q4.2\",\"q4.3\", \"q4.4\", \"q4.5\", \"q4.6\", \"q4.7\", \"q4.8\", \"q49\"]\n",
    "df_2009 = df_2009.merge(PHQ9_2009[PHQ9_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PHQ9_2016[PHQ9_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(PHQ9_features_2009, PHQ9_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'target_feature'\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "massive-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['target_feature'] = (df_2016['Intrusion_T4'] > 7).astype(int)\n",
    "df_2009['Intrusion_T4'] = df_2009_4[intrusion_features_2009].sum(axis=1)\n",
    "df_2009['target_feature'] = (df_2009['Intrusion_T4'] > 7).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-solomon",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009[target_feature].isna()]\n",
    "df_2016 = df_2016[~df_2016[target_feature].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-philadelphia",
   "metadata": {},
   "source": [
    "## 2009 data outer CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-bacteria",
   "metadata": {},
   "source": [
    "## parameters init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sufficient-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# class weight\n",
    "pos_sample = df_2009[target_feature].sum() \n",
    "all_samples = df_2009[target_feature].count()\n",
    "class_weights = all_samples/ pos_sample\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "   # ('RFE', RFE(CatBoostClassifier(verbose=0, random_state=random_state))),\n",
    "    ('classifier', CatBoostClassifier(verbose=0, random_state=random_state))])\n",
    "grid_params = [{\n",
    " #       'RFE__n_features_to_select': [15],\n",
    "        'classifier__class_weights':[[1, class_weights], [1, class_weights*2], [1, class_weights*0.5]],\n",
    "        'classifier__l2_leaf_reg': [3, 10, 75],\n",
    "        'classifier__depth': [5, 8]#, 9]\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2009, y_2009 = df_2009[X_features], df_2009[target_feature]\n",
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prostate-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6529222198612538, params = {'classifier__class_weights': [1, 2.746268656716418], 'classifier__depth': 8, 'classifier__l2_leaf_reg': 75}\n"
     ]
    }
   ],
   "source": [
    "x_2012, y_2012 = df_2016[df_2016['Wave']=='august12'][X_features], df_2016[df_2016['Wave']=='august12'][target_feature]\n",
    "\n",
    "clf.fit(x_2009, y_2009.astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "endangered-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.5421455938697318\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_2012)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_2012.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "endangered-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highschool_diploma 2.08712797052411\n",
      "ADHD 1.6178089744773274\n",
      "T1Acc1t 6.209533425501387\n",
      "T1Acc1n 4.527845244997182\n",
      "T1bias 12.639133443747355\n",
      "phq1 5.505947622248064\n",
      "trait1 7.764646379319579\n",
      "state1 7.7190131368085035\n",
      "PCL1 9.530020761056988\n",
      "q6.1_INTRU 3.970541860780802\n",
      "q6.2_DREAM 3.2577518658039053\n",
      "q6.3_FLASH 2.7154708999807617\n",
      "q6.4_UPSET 1.934639832870112\n",
      "q6.5_PHYS 1.7180874917854627\n",
      "T1q5.1 3.4033575843532367\n",
      "T1q5.2 3.1145805610731037\n",
      "T1q5.3 3.474897929002598\n",
      "T1q5.4 3.8083747289800725\n",
      "T1q5.5 5.084889948477361\n",
      "T1q5.6 1.515869843855303\n",
      "T1q5.7 1.8780815208446482\n",
      "T1q5.8 3.363062366372994\n",
      "T1q5.9 3.1593166071391603\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(X_features, clf.best_estimator_['classifier'].get_feature_importance()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-crisis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
