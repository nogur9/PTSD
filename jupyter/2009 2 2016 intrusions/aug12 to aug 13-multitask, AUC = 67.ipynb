{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "random_state = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 105)\n",
      "(724, 105)\n"
     ]
    }
   ],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "print(df_2016.shape)\n",
    "\n",
    "df_2016 =df_2016.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2016.shape)\n",
    "df_2016 = pd.concat((df_2016,pd.get_dummies(df_2016.Group)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicare",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ['bagrut', 'ADHD', 'Accuracy_threat_T1', 'Accuracy_NT_T1',\n",
    "              'Threat_Bias_T1', 'control', 'placebo', 'train_4',\n",
    "  'Accuracy_all_T1',\n",
    "  'Accuracy_neutral_T1',\n",
    "  'RT_all_T1',\n",
    "  'RT_neutral_NT_T1',\n",
    "  'RT_threat_NT_T1',\n",
    "  'RT_NT_T1',\n",
    " 'ABV_T1', 'PHQ_T1', 'Trait_T1', 'PCL_T1', 'Intrusion_T1',\n",
    "              'Avoidance_T1', 'Hyper_T1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-diary",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'target_feature'\n",
    "df_2016['target_feature'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "secondary_targets = ['Intrusion_T4', 'Avoidance_T4', 'Hyper_T4']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-solomon",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = (df_2016['bagrut'] == 'yes').astype(int)\n",
    "df_2016['dyslexia'] = (df_2016['dyslexia'] == 'yes').astype(int)\n",
    "df_2016['ADHD'] = (df_2016['ADHD'] == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wanted-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 110)\n"
     ]
    }
   ],
   "source": [
    "print(df_2016.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loaded-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 110)\n"
     ]
    }
   ],
   "source": [
    "df_2016 = df_2016[~df_2016['PCL_T4'].isna()]\n",
    "print(df_2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016[~df_2016['Intrusion_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Avoidance_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Hyper_T4'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opponent-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 110)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2013, y_2013 = df_2016[df_2016['Wave']=='august13'][X_features+ secondary_targets], df_2016[df_2016['Wave']=='august13'][target_feature]\n",
    "x_2012b, y_2012b = df_2016[(df_2016['Wave']=='nov12')][X_features+ secondary_targets], df_2016[(df_2016['Wave']=='nov12')][target_feature]\n",
    "\n",
    "x_2012, y_2012 = df_2016[(df_2016['Wave']=='august12')][X_features+ secondary_targets], df_2016[(df_2016['Wave']=='august12')][target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "matched-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "understood-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 1.0\n",
      "roc_auc = 0.6216216216216216\n",
      "roc_auc = 0.7083333333333333\n",
      "roc_auc = 1.0\n",
      "roc_auc = 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(x_2012, y_2012):\n",
    "    x_train, y_train = x_2012.iloc[train], y_2012.iloc[train]\n",
    "    x_test, y_test = x_2012.iloc[test], y_2012.iloc[test]\n",
    "\n",
    "    train_targets = x_train[secondary_targets]\n",
    "    test_targets = x_test[secondary_targets]\n",
    "    \n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "    \n",
    "    lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "    \n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "\n",
    "    lr_intrusion.fit(x_train, train_targets['Intrusion_T4'])\n",
    "    lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'])\n",
    "    lr_hyper.fit(x_train, train_targets['Hyper_T4'])\n",
    "\n",
    "    \n",
    "    intrusion_train = lr_intrusion.predict(x_train)\n",
    "    avoidance_train = lr_avoidnce.predict(x_train)\n",
    "    hyper_train = lr_hyper.predict(x_train)\n",
    "\n",
    "    intrusion = lr_intrusion.predict(x_test)\n",
    "    avoidance = lr_avoidnce.predict(x_test)\n",
    "    hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "    \n",
    "    y_pred_target = (intrusion + avoidance + hyper ) / 70\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "biblical-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6742857142857143\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2012, y_2012\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "train_targets = x_train[secondary_targets]\n",
    "test_targets = x_test[secondary_targets]\n",
    "    \n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "# ss = StandardScaler()\n",
    "# x_train = ss.fit_transform(x_train[X_features])\n",
    "# x_test = ss.transform(x_test[X_features])\n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, train_targets['Intrusion_T4'])\n",
    "lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'])\n",
    "lr_hyper.fit(x_train, train_targets['Hyper_T4'])\n",
    "\n",
    "    \n",
    "intrusion_train = lr_intrusion.predict(x_train)\n",
    "avoidance_train = lr_avoidnce.predict(x_train)\n",
    "hyper_train = lr_hyper.predict(x_train)\n",
    "    \n",
    "    \n",
    "intrusion = lr_intrusion.predict(x_test)\n",
    "avoidance = lr_avoidnce.predict(x_test)\n",
    "hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "y_pred_target = (intrusion + avoidance + hyper) / 70\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-apparatus",
   "metadata": {},
   "source": [
    "## normal classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "revolutionary-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.7837837837837838\n",
      "roc_auc = 0.6216216216216216\n",
      "roc_auc = 0.4444444444444445\n",
      "roc_auc = 0.9305555555555556\n",
      "roc_auc = 0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(x_2012, y_2012):\n",
    "    x_train, y_train = x_2012.iloc[train], y_2012.iloc[train]\n",
    "    x_test, y_test = x_2012.iloc[test], y_2012.iloc[test]\n",
    "\n",
    "\n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "\n",
    "\n",
    "    lr_pcl = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "\n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "    lr_pcl.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_target = lr_pcl.predict_proba(x_test)\n",
    "\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "quick-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.5953246753246753\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2012, y_2012\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "\n",
    "lr_pcl = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "    \n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "lr_pcl.fit(x_train, y_train)\n",
    "\n",
    "y_pred_target = lr_pcl.predict_proba(x_test)\n",
    "\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "advance-machinery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
