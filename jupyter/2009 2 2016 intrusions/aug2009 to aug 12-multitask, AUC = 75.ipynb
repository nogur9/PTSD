{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_state = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "humanitarian-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1103, 179)\n",
      "(1103, 179)\n"
     ]
    }
   ],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n",
    "\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009 = df_2009.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2009.shape)\n",
    "\n",
    "df_2009['control'] = np.ones_like(df_2009.ID)\n",
    "df_2009['placebo'] = np.zeros_like(df_2009.ID)\n",
    "df_2009['train_4'] = np.zeros_like(df_2009.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 105)\n"
     ]
    }
   ],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "#df_2016 = df_2016[(df_2016['Wave']=='august12')]\n",
    "\n",
    "\n",
    "df_2016 =df_2016.drop_duplicates(subset=\"ID\")\n",
    "#df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n",
    "print(df_2016.shape)\n",
    "df_2016 = pd.concat((df_2016,pd.get_dummies(df_2016.Group)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicare",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "sustainable-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "    'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    "  'Accuracy_threat_T1': 'T1Acc1t',\n",
    "  'Accuracy_NT_T1': 'T1Acc1n',\n",
    "  'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " 'Trait_T1': 'trait1',\n",
    " 'State_T1': 'state1',\n",
    " 'PCL_T1': 'PCL1',\n",
    " 'Intrusion_T1':'Intrusion_T1',\n",
    "    'Avoidance_T1': 'Avoidance_T1',\n",
    "    'Hyper_T1': 'Hyper_T1',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-diary",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "artificial-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009_1 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "avoidance_features_2009 = [\"q6.6_AVTHT\", \"q6.7_AVSIT\", \"q6.8_AMNES\", \"q6.9_DISINT\", \"q6.10_DTACH\",\n",
    "             \"q6.11_NUMB\", \"q6.12_FUTRE\"]\n",
    "hyper_features_2009 = [\"q6.13_SLEEP\", \"q6.14_ANGER\", \"q6.15_CONC\", \"q6.16_HYPER\", \"q6.17_STRTL\"]\n",
    "\n",
    "\n",
    "df_2009_1 = df_2009.merge(PCL_2009_1[intrusion_features_2009 +avoidance_features_2009+hyper_features_2009+ [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2009['Intrusion_T1'] = df_2009_1[intrusion_features_2009].sum(axis=1)\n",
    "df_2009['Avoidance_T1'] = df_2009_1[avoidance_features_2009].sum(axis=1)\n",
    "df_2009['Hyper_T1'] = df_2009_1[hyper_features_2009].sum(axis=1)\n",
    "\n",
    "trans_2016_2009_features['Intrusion_T1']= 'Intrusion_T1'\n",
    "trans_2016_2009_features['Avoidance_T1']= 'Avoidance_T1'\n",
    "trans_2016_2009_features['Hyper_T1']= 'Hyper_T1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "monetary-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009_3 = pd.read_excel(os.path.join(data_path_2009, \"questionnaire6PCL3.xlsx\"))\n",
    "\n",
    "\n",
    "\n",
    "PCL_2009_3 = df_2009.merge(PCL_2009_3[intrusion_features_2009 +avoidance_features_2009+hyper_features_2009+ [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2009['Intrusion_T4'] = PCL_2009_3[intrusion_features_2009].sum(axis=1)\n",
    "df_2009['Avoidance_T4'] = PCL_2009_3[avoidance_features_2009].sum(axis=1)\n",
    "df_2009['Hyper_T4'] = PCL_2009_3[hyper_features_2009].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'target_feature'\n",
    "secondary_targets = ['Intrusion_T4', 'Avoidance_T4', 'Hyper_T4']\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n",
    "\n",
    "df_2016['target_feature'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "df_2009['target_feature'] = (df_2009['PCL3'] > 39).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-solomon",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 110)\n",
      "(1103, 189)\n"
     ]
    }
   ],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)\n",
    "print(df_2016.shape)\n",
    "print(df_2009.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2016 = df_2016[~df_2016['Intrusion_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Avoidance_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['Hyper_T4'].isna()]\n",
    "df_2016 = df_2016[~df_2016['PCL_T4'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "empty-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009['Intrusion_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['Avoidance_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['Hyper_T4'].isna()]\n",
    "df_2009 = df_2009[~df_2009['PCL3'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "regulated-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 110)\n",
      "(725, 189)\n"
     ]
    }
   ],
   "source": [
    "print(df_2016.shape)\n",
    "print(df_2009.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "sufficient-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(5, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2016, y_2016 = df_2016[(df_2016['Wave']=='august12')][X_features+ secondary_targets], df_2016[(df_2016['Wave']=='august12')][target_feature]\n",
    "\n",
    "x_2009, y_2009 = df_2009[X_features+ secondary_targets], df_2009[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "patient-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2013, y_2013 = df_2016[df_2016['Wave']=='august13'][X_features+ secondary_targets], df_2016[df_2016['Wave']=='august13'][target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "understood-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.7647058823529412\n",
      "roc_auc = 0.7352941176470589\n",
      "roc_auc = 0.7803308823529411\n",
      "roc_auc = 0.7171916010498688\n",
      "roc_auc = 0.6861329833770778\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(x_2009, y_2009):\n",
    "    x_train, y_train = x_2009.iloc[train], y_2009.iloc[train]\n",
    "    x_test, y_test = x_2009.iloc[test], y_2009.iloc[test]\n",
    "    train_targets = x_train[secondary_targets]\n",
    "    test_targets = x_test[secondary_targets]\n",
    "    \n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "    \n",
    "    lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "    \n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "\n",
    "    lr_intrusion.fit(x_train, train_targets['Intrusion_T4'])\n",
    "    lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'])\n",
    "    lr_hyper.fit(x_train, train_targets['Hyper_T4'])\n",
    "\n",
    "    \n",
    "    intrusion_train = lr_intrusion.predict(x_train)\n",
    "    avoidance_train = lr_avoidnce.predict(x_train)\n",
    "    hyper_train = lr_hyper.predict(x_train)\n",
    "\n",
    "    intrusion = lr_intrusion.predict(x_test)\n",
    "    avoidance = lr_avoidnce.predict(x_test)\n",
    "    hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "    \n",
    "    y_pred_target = (intrusion + avoidance + hyper ) / 70\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "biblical-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2009, y_2009\n",
    "x_test, y_test = x_2016, y_2016\n",
    "\n",
    "train_targets = x_train[secondary_targets]\n",
    "test_targets = x_test[secondary_targets]\n",
    "    \n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, train_targets['Intrusion_T4'])\n",
    "lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'])\n",
    "lr_hyper.fit(x_train, train_targets['Hyper_T4'])\n",
    "\n",
    "    \n",
    "intrusion_train = lr_intrusion.predict(x_train)\n",
    "avoidance_train = lr_avoidnce.predict(x_train)\n",
    "hyper_train = lr_hyper.predict(x_train)\n",
    "    \n",
    "    \n",
    "intrusion = lr_intrusion.predict(x_test)\n",
    "avoidance = lr_avoidnce.predict(x_test)\n",
    "hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "y_pred_target = (intrusion + avoidance + hyper) / 70\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "received-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6311688311688312\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2009, y_2009\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "train_targets = x_train[secondary_targets]\n",
    "test_targets = x_test[secondary_targets]\n",
    "    \n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_avoidnce = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "lr_hyper = CatBoostRegressor(verbose=0, random_state=random_state)\n",
    "    \n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, train_targets['Intrusion_T4'])\n",
    "lr_avoidnce.fit(x_train, train_targets['Avoidance_T4'])\n",
    "lr_hyper.fit(x_train, train_targets['Hyper_T4'])\n",
    "\n",
    "    \n",
    "intrusion_train = lr_intrusion.predict(x_train)\n",
    "avoidance_train = lr_avoidnce.predict(x_train)\n",
    "hyper_train = lr_hyper.predict(x_train)\n",
    "    \n",
    "    \n",
    "intrusion = lr_intrusion.predict(x_test)\n",
    "avoidance = lr_avoidnce.predict(x_test)\n",
    "hyper = lr_hyper.predict(x_test)\n",
    "\n",
    "y_pred_target = (intrusion + avoidance + hyper) / 70\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-tulsa",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "molecular-pasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.7375919117647058\n",
      "roc_auc = 0.7095588235294117\n",
      "roc_auc = 0.7899816176470589\n",
      "roc_auc = 0.7430008748906387\n",
      "roc_auc = 0.6673228346456693\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(x_2009, y_2009):\n",
    "    x_train, y_train = x_2009.iloc[train], y_2009.iloc[train]\n",
    "    x_test, y_test = x_2009.iloc[test], y_2009.iloc[test]\n",
    "    \n",
    "    x_train = x_train[X_features]\n",
    "    x_test = x_test[X_features]\n",
    "    \n",
    "    lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "    \n",
    "    mice = IterativeImputer(max_iter=1000)\n",
    "    x_train = mice.fit_transform(x_train)\n",
    "    x_test = mice.transform(x_test)\n",
    "\n",
    "    lr_intrusion.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "    y_pred_target = lr_intrusion.predict_proba(x_test)\n",
    "    print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "diagnostic-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6934065934065934\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2009, y_2009\n",
    "x_test, y_test = x_2016, y_2016\n",
    "\n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "y_pred_target = lr_intrusion.predict_proba(x_test)\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "numerous-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.5703896103896103\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_2009, y_2009\n",
    "x_test, y_test = x_2013, y_2013\n",
    "\n",
    "x_train = x_train[X_features]\n",
    "x_test = x_test[X_features]\n",
    " \n",
    "    \n",
    "lr_intrusion = CatBoostClassifier(verbose=0, random_state=random_state)\n",
    "\n",
    "mice = IterativeImputer(max_iter=1000)\n",
    "x_train = mice.fit_transform(x_train)\n",
    "x_test = mice.transform(x_test)\n",
    "\n",
    "\n",
    "lr_intrusion.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "y_pred_target = lr_intrusion.predict_proba(x_test)\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target[:, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-basement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
