{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "#from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# seed\n",
    "# import os\n",
    "# import random\n",
    "# os.environ['PYTHONHASHSEED']=str(271828)\n",
    "# random.seed(271828)\n",
    "# np.random.seed(271828)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCL_calculator(df):\n",
    "\n",
    "    symptomatic_cutoff = 2\n",
    "    intrusion = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH', 'q6.4_UPSET', 'q6.5_PHYS']\n",
    "    avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES', 'q6.9_DISINT', 'q6.10_DTACH',\n",
    "                 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "    tred = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH']\n",
    "    only_avoidance = ['q6.6_AVTHT', 'q6.7_AVSIT', 'q6.8_AMNES']\n",
    "    hypertension = ['q6.13_SLEEP', 'q6.14_ANGER', 'q6.15_CONC', 'q6.16_HYPER', 'q6.17_STRTL']\n",
    "    depression = ['q6.9_DISINT', 'q6.10_DTACH', 'q6.11_NUMB', 'q6.12_FUTRE']\n",
    "\n",
    "    df[intrusion + avoidance + hypertension].fillna(df[intrusion + avoidance + hypertension].mean(axis=1))\n",
    "    intrusion_cuoff = 1\n",
    "    avoidance_cuoff = 3\n",
    "    hypertension_cuoff = 2\n",
    "    only_avoidance_cutoff = 1\n",
    "    depression_cutoff = 2\n",
    "    tred_cutoff = 1\n",
    "\n",
    "    df['PCL_score'] = (df[intrusion + avoidance + hypertension]).sum(axis=1)\n",
    "    df['PCL_mean'] = (df[intrusion + avoidance + hypertension]).mean(axis=1)\n",
    "    df['PCL_std'] = (df[intrusion + avoidance + hypertension]).std(axis=1)\n",
    "    \n",
    "\n",
    "    df['intrusion'] = (df[intrusion] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['intrusion_mean'] = (df[intrusion] > symptomatic_cutoff).mean(axis=1)\n",
    "    df['intrusion_std'] = (df[intrusion] > symptomatic_cutoff).std(axis=1)\n",
    "    df['intrusion_cutoff'] = (df['intrusion'] >= intrusion_cuoff).astype(int)\n",
    "\n",
    "    df['avoidance'] = (df[avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['avoidance_mean'] = (df[avoidance] > symptomatic_cutoff).mean(axis=1)\n",
    "    df['avoidance_std'] = (df[avoidance] > symptomatic_cutoff).std(axis=1)\n",
    "    df['avoidance_cutoff'] = (df['avoidance'] >= avoidance_cuoff).astype(int)\n",
    "\n",
    "    df['depression'] = (df[depression] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['depression_mean'] = (df[depression] > symptomatic_cutoff).mean(axis=1)\n",
    "    df['depression_std'] = (df[depression] > symptomatic_cutoff).std(axis=1)\n",
    "    df['depression_cutoff'] = (df['depression'] >= depression_cutoff).astype(int)\n",
    "\n",
    "    df['hypertention'] = (df[hypertension] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['hypertention_mean'] = (df[hypertension] > symptomatic_cutoff).mean(axis=1)\n",
    "    df['hypertention_std'] = (df[hypertension] > symptomatic_cutoff).std(axis=1)\n",
    "    df['hypertention_cutoff'] = (df['hypertention'] >= hypertension_cuoff).astype(int)\n",
    "\n",
    "    df['tred'] = (df[tred] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['tred_mean'] = (df[tred] > symptomatic_cutoff).mean(axis=1)\n",
    "    df['tred_std'] = (df[tred] > symptomatic_cutoff).std(axis=1)\n",
    "    df['tred_cutoff'] = df['tred'] >= tred_cutoff\n",
    "\n",
    "    df['only_avoidance'] = (df[only_avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['only_avoidance_mean'] = (df[only_avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['only_avoidance_std'] = (df[only_avoidance] > symptomatic_cutoff).sum(axis=1)\n",
    "    df['only_avoidance_cutoff'] = df['only_avoidance'] >= only_avoidance_cutoff\n",
    "\n",
    "    #df['regression_cutoff_33'] = df['sum'] >= 33\n",
    "    #df['regression_cutoff_50'] = df['sum'] >= 49\n",
    "    df['diagnosis'] = ((df['hypertention_cutoff']) & (df['avoidance_cutoff']) & (df['intrusion_cutoff']) & (df['PCL_score'] >= 49))\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\‏‏PycharmProjects\\PTSD\\Data\\PTSD.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "#combine with specifics of answers\n",
    "df_pcl2 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL2.xlsx\")\n",
    "df_pcl2 = PCL_calculator(df_pcl2)\n",
    "\n",
    "df_pcl1 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL1.xlsx\")\n",
    "df_pcl1 = PCL_calculator(df_pcl1)\n",
    "\n",
    "df = df.merge(df_pcl1, on=\"ID\", how='outer')\n",
    "df = df.merge(df_pcl2, suffixes=('_pcl1', '_pcl2'), on=\"ID\", how='outer')\n",
    "\n",
    "df_pcl3 = pd.read_excel(\"C:\\‏‏PycharmProjects\\PTSD\\Data\\questionnaire6PCL3.xlsx\")\n",
    "df_pcl3 = PCL_calculator(df_pcl3)\n",
    "df = df.merge(df_pcl3.drop(['PCL3_Strict', 'pcl3', 'PCL3_Broad'], axis=1), on=\"ID\", how='outer')\n",
    "# rmoving missing Y's\n",
    "df = df[~df['tred_cutoff'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\"T2Acc1t\", \"T2Acc1n\", \"military_exposure_unit\",\n",
    "    \"highschool_diploma\", \"dyslexia\", \"ADHD\", \"T1Acc1t\", \"T1Acc1n\", \"T1bias\", 'Ashken_scale', 'Sephar_scale',\n",
    "            \"phq1\", \"lot1\", \"trait1\",\n",
    "                \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\",\n",
    "                \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\",\n",
    "                \"humor1\",\n",
    "                \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\", \"planning2\",\n",
    "                \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\",\n",
    "                \"instrumental_support2\",\n",
    "                \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\",\n",
    "                \"self_blame2\",\n",
    "                \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", 'q6.1_INTRU_pcl1', \n",
    "                'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                  'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                  'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                  'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                  'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                  'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                  'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                  'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2',\n",
    "            \n",
    "            'PCL_score_pcl1', 'PCL_mean_pcl1', 'PCL_std_pcl1', 'intrusion_pcl1', 'intrusion_mean_pcl1', 'intrusion_std_pcl1',\n",
    "            'intrusion_cutoff_pcl1', 'avoidance_pcl1', 'avoidance_mean_pcl1', 'avoidance_std_pcl1', 'avoidance_cutoff_pcl1', \n",
    "            'depression_pcl1', 'depression_mean_pcl1', 'depression_std_pcl1', 'depression_cutoff_pcl1', 'hypertention_pcl1',\n",
    "            'hypertention_mean_pcl1', 'hypertention_std_pcl1', 'hypertention_cutoff_pcl1', 'tred_pcl1', 'tred_mean_pcl1', \n",
    "            'tred_std_pcl1', 'tred_cutoff_pcl1', 'only_avoidance_pcl1','only_avoidance_mean_pcl1', 'only_avoidance_std_pcl1', \n",
    "            'only_avoidance_cutoff_pcl1',\n",
    "            \n",
    "            'PCL_score_pcl2', 'PCL_mean_pcl2', 'PCL_std_pcl2', 'intrusion_pcl2', 'intrusion_mean_pcl2', 'intrusion_std_pcl2',\n",
    "            'intrusion_cutoff_pcl2', 'avoidance_pcl2', 'avoidance_mean_pcl2', 'avoidance_std_pcl2', 'avoidance_cutoff_pcl2', \n",
    "            'depression_pcl2', 'depression_mean_pcl2', 'depression_std_pcl2', 'depression_cutoff_pcl2', 'hypertention_pcl2',\n",
    "            'hypertention_mean_pcl2', 'hypertention_std_pcl2', 'hypertention_cutoff_pcl2', 'tred_pcl2', 'tred_mean_pcl2', \n",
    "            'tred_std_pcl2', 'tred_cutoff_pcl2', 'only_avoidance_pcl2','only_avoidance_mean_pcl2', 'only_avoidance_std_pcl2', \n",
    "            'only_avoidance_cutoff_pcl2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = [\"age\", \"highschool_diploma\", \"dyslexia\", \"ADHD\", \"phq1\", \"lot1\",\n",
    "                    \"trait1\", \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"phq2\", \"lot2\",\n",
    "                    \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\", \"PCL_Strict2\", \"cd_risc1\", \"active_coping1\",\n",
    "                    \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\", \"religion1\",\n",
    "                    \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                    \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"active_coping2\",\n",
    "                    \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\", \"religion2\", \"emotional_support2\",\n",
    "                    \"instrumental_support2\", \"self_distraction2\", \"denial2\", \"venting2\", \"substance_use2\",\n",
    "                    \"behavioral_disengagement2\", \"self_blame2\", \"trauma_history8_1\",\n",
    "                    'q6.1_INTRU_pcl1', 'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                    'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                    'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                    'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                    'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                    'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                    'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                    'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2',\n",
    "                    'intrusion_cutoff', 'avoidance_cutoff', 'hypertention_cutoff', 'regression_cutoff_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_features = [\"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\"]\n",
    "continuous_features = [\"T1Acc1t\", \"T1Acc1n\", \"T1bias\"]\n",
    "t2_features = [\n",
    "    \"lot2\", \"trait2\", \"state2\", \"PCL2\", \"PCL_Broad2\", \"PCL_Strict2\", \"phq2\",\n",
    "\n",
    "    \"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\", \n",
    "    \"religion2\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\n",
    "    \"denial2\", \"venting2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\",\n",
    "    \n",
    "    'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2', 'q6.5_PHYS_pcl2',\n",
    "    'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                    'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                    'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2'\n",
    "]\n",
    "t1_features =[ \"phq1\", \"lot1\", \"trait1\",\"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\",\n",
    "              \n",
    "                    \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\", \"religion1\",\n",
    "                    \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                    \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\",\n",
    "                'q6.1_INTRU_pcl1', 'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                    'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                    'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                    'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_targets = ['q6.1_INTRU', 'q6.2_DREAM', 'q6.3_FLASH']\n",
    "target_feature = ['tred_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[features + mtl_targets + target_feature]\n",
    "\n",
    "#df1 = df1.dropna(thresh=47)\n",
    "df_t1 = df1[t1_features]\n",
    "df_t2 = df1[t2_features]\n",
    "df1 = df1[(df_t1.isna().astype(int).sum(axis=1)<38) | (df_t2.isna().astype(int).sum(axis=1)<38)]\n",
    "df1[\"t1_missing\"] = df_t1.isna().astype(int).sum(axis=1)==38\n",
    "df1[\"t2_missing\"] = df_t2.isna().astype(int).sum(axis=1)==38\n",
    "features.extend([\"t1_missing\", \"t2_missing\"])\n",
    "\n",
    "impute = 1\n",
    "if impute:\n",
    "    for i in mtl_targets:\n",
    "        df1[i] = df[i].fillna(0)\n",
    "    mice = IterativeImputer()\n",
    "    df1 = pd.DataFrame(mice.fit_transform(df1), columns=df1.columns)\n",
    "    #Y = Y.fillna(Y.mean())\n",
    "    features.extend([\"outliers_count_t1_35\", \"outliers_count_t2_35\", \"outliers_count_t1_25\", \"outliers_count_t2_25\"])\n",
    "    df1[\"outliers_count_t1_35\"] = (np.abs(stats.zscore(df1[t1_features])) > 3.5).sum(axis=1)\n",
    "    df1[\"outliers_count_t1_25\"] = (np.abs(stats.zscore(df1[t1_features])) > 2.5).sum(axis=1)\n",
    "    df1[\"outliers_count_t2_35\"] = (np.abs(stats.zscore(df1[t2_features])) > 3.5).sum(axis=1)\n",
    "    df1[\"outliers_count_t2_25\"] = (np.abs(stats.zscore(df1[t2_features])) > 2.5).sum(axis=1)\n",
    "    \n",
    "    \n",
    "#df1 = df1[(np.abs(stats.zscore(df1)) > 3).sum(axis=1)<15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[features] =StandardScaler().fit_transform(df1[features]), columns=df1.columns)\n",
    "df1['std_genome'] = df1[genome_features].std(axis=1)\n",
    "df1['std_t2'] = df1[[ \"trait2\", \"state2\", \"PCL2\"]].std(axis=1)\n",
    "df1['std_t1'] = df1[[ \"trait1\", \"state1\", \"PCL1\"]].std(axis=1)\n",
    "\n",
    "df1['std_pos_coping_t1'] = df1[[\"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\", \"humor1\",\n",
    "                \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\",\"venting1\"]].std(axis=1)\n",
    "\n",
    "df1['std_neg_coping_t1'] = df1[[\"denial1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\"]].std(axis=1)\n",
    "\n",
    "df1['std_pos_coping_t2'] = df1[[\"active_coping2\", \"planning2\", \"positive_reframing2\", \"acceptance2\", \"humor2\",\n",
    "                \"religion1\", \"emotional_support2\", \"instrumental_support2\", \"self_distraction2\",\"venting2\"]].std(axis=1)\n",
    "\n",
    "df1['std_neg_coping_t2'] = df1[[\"denial2\", \"substance_use2\", \"behavioral_disengagement2\", \"self_blame2\"]].std(axis=1)\n",
    "\n",
    "features = features + ['std_genome', 'std_t1', 'std_t2', 'std_pos_coping_t1', 'std_neg_coping_t1', 'std_pos_coping_t2', 'std_neg_coping_t2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t1_features:\n",
    "    df1[\"delta_\"+i[:len(i)-1:]] = df1[i] - df1[i[:len(i)-1:]+\"2\"]\n",
    "    features = features + [\"delta_\"+i[:len(i)-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_features = ['std_genome', 'std_t1', 'std_t2', 'std_pos_coping_t1', 'std_neg_coping_t1', 'std_pos_coping_t2', 'std_neg_coping_t2'] + continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "#for i in z_features:\n",
    " #   df1[i + \"_z_Score\"] = stats.zscore(df1[i])\n",
    "  #  features = features + [i + \"_z_Score\"]\n",
    "for i in genome_features:\n",
    "    for j in ['Ashken_scale', 'Sephar_scale']:\n",
    "        df1[i + \"_\" + j] = df1[i] * df1[j] * 0.01\n",
    "        features = features + [i + \"_\" + j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "m = ols('PCL_score_pcl2 ~ PCL_score_pcl1 + phq1 + lot1 + trait1 + state1 + active_coping1 + '\\\n",
    "        'planning1 + positive_reframing1 + acceptance1 + humor1 + religion1 + emotional_support1 + '\\\n",
    "        'instrumental_support1 + self_distraction1 + denial1 + venting1 + substance_use1 + '\\\n",
    "        'behavioral_disengagement1 + self_blame1',df1).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "df1[['cooks_d_PCL_score_pcl2', 'dffits_PCL_score_pcl2', 'standard_resid_PCL_score_pcl2']] = sm_fr[['cooks_d', 'dffits', 'standard_resid']]\n",
    "features = features + ['cooks_d_PCL_score_pcl2', 'dffits_PCL_score_pcl2', 'standard_resid_PCL_score_pcl2']\n",
    "\n",
    "\n",
    "m = ols('intrusion_pcl2 ~ PCL_score_pcl1 + phq1 + lot1 + trait1 + state1 + active_coping1 + '\\\n",
    "        'planning1 + positive_reframing1 + acceptance1 + humor1 + religion1 + emotional_support1 + '\\\n",
    "        'instrumental_support1 + self_distraction1 + denial1 + venting1 + substance_use1 + '\\\n",
    "        'behavioral_disengagement1 + self_blame1',df1).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "df1[['cooks_d_intrusion_pcl2', 'dffits_intrusion_pcl2', 'standard_resid_intrusion_pcl2']] = sm_fr[['cooks_d', 'dffits', 'standard_resid']]\n",
    "features = features + ['cooks_d_intrusion_pcl2', 'dffits_intrusion_pcl2', 'standard_resid_intrusion_pcl2']\n",
    "\n",
    "\n",
    "\n",
    "m = ols('avoidance_pcl2 ~ PCL_score_pcl1 + phq1 + lot1 + trait1 + state1 + active_coping1 + '\\\n",
    "        'planning1 + positive_reframing1 + acceptance1 + humor1 + religion1 + emotional_support1 + '\\\n",
    "        'instrumental_support1 + self_distraction1 + denial1 + venting1 + substance_use1 + '\\\n",
    "        'behavioral_disengagement1 + self_blame1',df1).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "df1[['cooks_d_avoidance_pcl2', 'dffits_avoidance_pcl2', 'standard_resid_avoidance_pcl2']] = sm_fr[['cooks_d', 'dffits', 'standard_resid']]\n",
    "features = features + ['cooks_d_avoidance_pcl2', 'dffits_avoidance_pcl2', 'standard_resid_avoidance_pcl2']\n",
    "\n",
    "\n",
    "m = ols('depression_pcl2 ~ PCL_score_pcl1 + phq1 + lot1 + trait1 + state1 + active_coping1 + '\\\n",
    "        'planning1 + positive_reframing1 + acceptance1 + humor1 + religion1 + emotional_support1 + '\\\n",
    "        'instrumental_support1 + self_distraction1 + denial1 + venting1 + substance_use1 + '\\\n",
    "        'behavioral_disengagement1 + self_blame1',df1).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "df1[['cooks_d_depression_pcl2', 'dffits_depression_pcl2', 'standard_resid_depression_pcl2']] = sm_fr[['cooks_d', 'dffits', 'standard_resid']]\n",
    "features = features + ['cooks_d_depression_pcl2', 'dffits_depression_pcl2', 'standard_resid_depression_pcl2']\n",
    "\n",
    "\n",
    "m = ols('hypertention_pcl2 ~ PCL_score_pcl1 + phq1 + lot1 + trait1 + state1 + active_coping1 + '\\\n",
    "        'planning1 + positive_reframing1 + acceptance1 + humor1 + religion1 + emotional_support1 + '\\\n",
    "        'instrumental_support1 + self_distraction1 + denial1 + venting1 + substance_use1 + '\\\n",
    "        'behavioral_disengagement1 + self_blame1',df1).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "df1[['cooks_d_hypertention_pcl2', 'dffits_hypertention_pcl2', 'standard_resid_hypertention_pcl2']] = sm_fr[['cooks_d', 'dffits', 'standard_resid']]\n",
    "features = features + ['cooks_d_hypertention_pcl2', 'dffits_hypertention_pcl2', 'standard_resid_hypertention_pcl2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useless_features = [\"dyslexia\",\"T1Acc1n\", 'Ashken_scale', 'Sephar_scale', \"phq1\", \"lot1\", \"trait1\",\n",
    "                \"state1\", \"PCL1\", \"PCL_Broad1\", \"PCL_Strict1\", \"state2\", \"PCL_Broad2\",\n",
    "                \"PCL_Strict2\", \"active_coping1\", \"planning1\", \"positive_reframing1\", \"acceptance1\",\n",
    "                \"humor1\", \"religion1\", \"emotional_support1\", \"instrumental_support1\", \"self_distraction1\", \"denial1\",\n",
    "                \"venting1\", \"substance_use1\", \"behavioral_disengagement1\", \"self_blame1\", \"planning2\",\n",
    "                \"religion2\", \"instrumental_support2\", \"venting2\", \"behavioral_disengagement2\",\n",
    "                \"trauma_history8_1\", \"HML_5HTT\", \"HL_MAOA\", \"HML_NPY\", \"COMT_Hap1_recode\",\n",
    "                \"COMT_Hap2_recode\", \"COMT_Hap1_LvsMH\", \"HML_FKBP5\", 'q6.1_INTRU_pcl1', \n",
    "                'q6.2_DREAM_pcl1', 'q6.3_FLASH_pcl1', 'q6.4_UPSET_pcl1',\n",
    "                  'q6.5_PHYS_pcl1', 'q6.6_AVTHT_pcl1', 'q6.7_AVSIT_pcl1', 'q6.8_AMNES_pcl1', 'q6.9_DISINT_pcl1',\n",
    "                  'q6.10_DTACH_pcl1', 'q6.11_NUMB_pcl1', 'q6.12_FUTRE_pcl1', 'q6.13_SLEEP_pcl1',\n",
    "                  'q6.14_ANGER_pcl1', 'q6.15_CONC_pcl1', 'q6.16_HYPER_pcl1', 'q6.17_STRTL_pcl1',\n",
    "                \n",
    "                    'q6.1_INTRU_pcl2', 'q6.2_DREAM_pcl2', 'q6.3_FLASH_pcl2', 'q6.4_UPSET_pcl2',\n",
    "                  'q6.5_PHYS_pcl2', 'q6.6_AVTHT_pcl2', 'q6.7_AVSIT_pcl2', 'q6.8_AMNES_pcl2', 'q6.9_DISINT_pcl2',\n",
    "                  'q6.10_DTACH_pcl2', 'q6.11_NUMB_pcl2', 'q6.12_FUTRE_pcl2', 'q6.13_SLEEP_pcl2',\n",
    "                  'q6.14_ANGER_pcl2', 'q6.15_CONC_pcl2', 'q6.16_HYPER_pcl2', 'q6.17_STRTL_pcl2',\n",
    "            \n",
    "            'PCL_score_pcl1', 'PCL_mean_pcl1', 'intrusion_mean_pcl1', 'intrusion_cutoff_pcl1', 'avoidance_pcl1',\n",
    "            'avoidance_mean_pcl1', 'avoidance_std_pcl1', 'avoidance_cutoff_pcl1', \n",
    "            'depression_pcl1', 'depression_mean_pcl1', 'depression_cutoff_pcl1', 'hypertention_pcl1',\n",
    "            'hypertention_mean_pcl1', 'hypertention_cutoff_pcl1', 'tred_pcl1', 'tred_mean_pcl1', \n",
    "            'tred_std_pcl1', 'tred_cutoff_pcl1', 'only_avoidance_pcl1','only_avoidance_mean_pcl1', 'only_avoidance_std_pcl1', \n",
    "            'only_avoidance_cutoff_pcl1',\n",
    "            \n",
    "            'PCL_score_pcl2', 'PCL_mean_pcl2', 'PCL_std_pcl2', 'intrusion_pcl2',\n",
    "            'intrusion_cutoff_pcl2',  'avoidance_cutoff_pcl2', \n",
    "            'depression_pcl2', 'depression_mean_pcl2', 'depression_cutoff_pcl2', 'hypertention_pcl2',\n",
    "            'hypertention_cutoff_pcl2', 'tred_pcl2', 'tred_mean_pcl2', \n",
    "            'tred_std_pcl2', 'tred_cutoff_pcl2', 'only_avoidance_pcl2','only_avoidance_mean_pcl2', \n",
    "                    'only_avoidance_std_pcl2', \n",
    "            'only_avoidance_cutoff_pcl2']\n",
    "\n",
    "\n",
    "features = [i for i in features if i not in useless_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut off the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_out, Y, y_out = train_test_split(df1[features + mtl_targets], df1[target_feature[0]],\n",
    "                                      test_size=0.25, random_state=271828, stratify=df1[target_feature[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=271828)\n",
    "ss, tt = StandardScaler(), StandardScaler()\n",
    "X_train, X_test = pd.DataFrame(np.hstack([ss.fit_transform(X_train[features]), X_train[mtl_targets]]), columns=X_train.columns), pd.DataFrame(np.hstack([tt.fit_transform(X_test[features]), X_test[mtl_targets]]), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(10, random_state=271828)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV model of roc auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epochs= 1500 \n",
      "activation= relu \n",
      "patience= 10 \n",
      "dropout_rate = 0.9 \n",
      "loss_weight = 0.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'regularizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-31f231ac4089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mvisible\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmtl_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     x = Dense(20, activation=activation, kernel_regularizer=regularizers.l2(0.01),\n\u001b[0m\u001b[0;32m     20\u001b[0m                 activity_regularizer=regularizers.l1(0.01))(visible)\n\u001b[0;32m     21\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regularizers' is not defined"
     ]
    }
   ],
   "source": [
    "for activation in ['relu']: # ''\n",
    "    for dropout_rate in [0.9, 0.75, 0.5]: #200\n",
    "        for loss_weights in [0.1, 1]:#, 2]: # \n",
    "            for patience in [10, 25, 75]:#, 23]:\n",
    "                epochs = 1500\n",
    "                print(\"\\nepochs=\", epochs, \"\\nactivation=\", activation, \"\\npatience=\", patience,\n",
    "                      \"\\ndropout_rate =\", dropout_rate, \"\\nloss_weight =\", loss_weights)\n",
    "                \n",
    "                scores_f = []\n",
    "                #scores_p = []\n",
    "                #scores_r = []\n",
    "                scores_auc = []\n",
    "                \n",
    "                for train, test in cv.split(X_train, y_train):\n",
    "                    X_train_cv = X_train.iloc[train]\n",
    "                    y_train_cv = y_train.iloc[train]\n",
    "\n",
    "                    visible = Input(shape=(X_train.shape[1] - len(mtl_targets),))\n",
    "                    x = Dense(20, activation=activation, kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(visible)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "                    x = Dense(20, activation=activation, kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(x)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x = Dropout(dropout_rate)(x)\n",
    "                    \n",
    "                    outputs = [Dense(1, activation='sigmoid')(x)] * (len(mtl_targets) + 1)\n",
    "                    \n",
    "                    es = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "                    model = Model(inputs=visible, outputs=outputs)\n",
    "\n",
    "                    model.compile(loss=[\"mean_squared_error\"] * (len(mtl_targets)) + [\"binary_crossentropy\"],\n",
    "                              optimizer='adam', loss_weights = [loss_weights] * len(mtl_targets) + [1])\n",
    "                    \n",
    "                    targets = [X_train_cv[i] for i in mtl_targets] + [y_train_cv]\n",
    "                    \n",
    "                    X_train_cv.drop(mtl_targets, axis=1, inplace=True)\n",
    "                    \n",
    "                    #class_weight = [{0:1, 1:4}] * len(mtl_targets) + [{0:1, 1:19}]\n",
    "                \n",
    "                    \n",
    "                    model.fit(X_train_cv, targets, epochs=epochs, validation_split= 0.1, callbacks=[es], verbose=0)\n",
    "                    y_pred = model.predict(X_train[features].iloc[test])[len(mtl_targets)]                   \n",
    "\n",
    "                    fpr, tpr, threshold = roc_curve(y_train.iloc[test], y_pred)\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                    # method I: plt\n",
    "                    plt.title('Receiver Operating Characteristic')\n",
    "                    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "                    plt.legend(loc = 'lower right')\n",
    "                    plt.plot([0, 1], [0, 1],'r--')\n",
    "                    plt.xlim([0, 1])\n",
    "                    plt.ylim([0, 1])\n",
    "                    plt.ylabel('True Positive Rate')\n",
    "                    plt.xlabel('False Positive Rate')\n",
    "                    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_f = []\n",
    "scores_p = []\n",
    "scores_r = []\n",
    "scores_auc = []\n",
    "for depth in [2, 5]:\n",
    "    for class_weights in [[1, 20]]:\n",
    "        for n_features_to_select in [25]:\n",
    "            for l2_leaf_reg in [10, 1, 0.1]:\n",
    "                print(\"depth=\",depth, \"l2_leaf_reg=\",l2_leaf_reg, \"class_weights=\",class_weights, \"n_features_to_select=\",n_features_to_select)\n",
    "                for train, test in cv.split(X_train, y_train.astype(int)):\n",
    "\n",
    "                    X_train_cv = X_train.iloc[train]\n",
    "                    y_train_cv = y_train.iloc[train]\n",
    "                    X_test_cv = X_train.iloc[test]\n",
    "                    t = [X_train_cv[i] for i in mtl_targets] + [y_train_cv]\n",
    "                    X_train_cv.drop(mtl_targets, axis=1, inplace=True)\n",
    "                    X_test_cv.drop(mtl_targets, axis=1, inplace=True)\n",
    "\n",
    "                    clf1 = Pipeline([\n",
    "                  #                ('feature_selection', RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=n_features_to_select)),\n",
    "                                  ('classification', CatBoostClassifier(verbose=0, class_weights=class_weights, depth=depth, l2_leaf_reg=l2_leaf_reg, loss_function='Logloss'))\n",
    "                                ])\n",
    "                    clf2 = Pipeline([\n",
    "                   #               ('feature_selection', RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=n_features_to_select)),\n",
    "                                  ('classification', CatBoostClassifier(verbose=0, class_weights=class_weights, depth=depth, l2_leaf_reg=l2_leaf_reg, loss_function='Logloss'))\n",
    "                                ])\n",
    "                    clf3 = Pipeline([\n",
    "                    #              ('feature_selection', RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=n_features_to_select)),\n",
    "                                  ('classification', CatBoostClassifier(verbose=0, class_weights=class_weights, depth=depth, l2_leaf_reg=l2_leaf_reg, loss_function='Logloss'))\n",
    "                                ])\n",
    "                    clf_target = Pipeline([\n",
    "                     #             ('feature_selection', RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=n_features_to_select)),\n",
    "                                  ('classification', CatBoostClassifier(verbose=0, class_weights=[class_weights[0], 4*class_weights[1]], depth=depth, l2_leaf_reg=l2_leaf_reg, loss_function='Logloss'))\n",
    "                                ])\n",
    "\n",
    "                    y_pred_1 = clf1.fit(X_train_cv, (t[0]).values.astype(int)).predict_proba(X_test_cv)\n",
    "                    y_pred_2 = clf2.fit(X_train_cv, (t[1]).values.astype(int)).predict_proba(X_test_cv)\n",
    "                    y_pred_3 = clf3.fit(X_train_cv, (t[2]).values.astype(int)).predict_proba(X_test_cv)\n",
    "                    y_pred_target = clf_target.fit(X_train_cv, t[3].values.astype(int)).predict_proba(X_test_cv)\n",
    "\n",
    "                    preds = (y_pred_1[:, 1] * y_pred_2[:, 1] *  y_pred_3[:, 1] * y_pred_target[:, 1]) > 0.02625 #+ 0.5 * y_pred_target[:, 1]) > 1\n",
    "\n",
    "                    fpr, tpr, threshold = roc_curve(y_train.iloc[test], preds)\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                    # method I: plt\n",
    "                    plt.title('Receiver Operating Characteristic')\n",
    "                    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "                    plt.legend(loc = 'lower right')\n",
    "                    plt.plot([0, 1], [0, 1],'r--')\n",
    "                    plt.xlim([0, 1])\n",
    "                    plt.ylim([0, 1])\n",
    "                    plt.ylabel('True Positive Rate')\n",
    "                    plt.xlabel('False Positive Rate')\n",
    "                    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = [X_train[i] for i in mtl_targets] + [y_train]\n",
    "X_train.drop(mtl_targets, axis=1, inplace=True)\n",
    "    \n",
    "y_pred_1 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=1000).fit(X_train, (t[0]).values.astype(int)).predict_proba(X_test)\n",
    "y_pred_2 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=1000).fit(X_train, (t[1]).values.astype(int)).predict_proba(X_test)\n",
    "y_pred_3 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=1000).fit(X_train, (t[2]).values.astype(int)).predict_proba(X_test)\n",
    "y_pred_target = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=1000).fit(X_train, t[3].values.astype(int)).predict_proba(X_test)\n",
    "\n",
    "y_pred = (y_pred_1[:, 1] * y_pred_2[:, 1] *  y_pred_3[:, 1] * y_pred_target[:, 1]) > 0.0625 #+ 0.5 * y_pred_target[:, 1]) > 1\n",
    "\n",
    "print(\"f1\", f1_score(y_test.astype(bool), y_pred))\n",
    "print(\"p\",precision_score(y_test.astype(bool), y_pred))\n",
    "print(\"r\",recall_score(y_test.astype(bool), y_pred))\n",
    "print(\"auc\", roc_auc_score(y_test.astype(bool), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_out, Y, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = [X[i] for i in mtl_targets] + [Y]\n",
    "X.drop(mtl_targets, axis=1, inplace=True)    \n",
    "y_pred_1 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=100).fit(X, (t[0]).values.astype(int)).predict_proba(X_out)\n",
    "y_pred_2 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=100).fit(X, (t[1]).values.astype(int)).predict_proba(X_out)\n",
    "y_pred_3 = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=100).fit(X, (t[2]).values.astype(int)).predict_proba(X_out)\n",
    "y_pred_target = CatBoostClassifier(verbose=0, loss_function='CrossEntropy', n_estimators=100).fit(X, t[3].values.astype(int)).predict_proba(X_out)\n",
    "\n",
    "y_pred = (y_pred_1[:, 1] * y_pred_2[:, 1] *  y_pred_3[:, 1] * y_pred_target[:, 1]) > 0.0625 #+ 0.5 * y_pred_target[:, 1]) > 1\n",
    "\n",
    "print(\"f1\", f1_score(y_out.astype(bool), y_pred))\n",
    "print(\"p\",precision_score(y_out.astype(bool), y_pred))\n",
    "print(\"r\",recall_score(y_out.astype(bool), y_pred))\n",
    "print(\"auc\", roc_auc_score(y_out.astype(bool), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
