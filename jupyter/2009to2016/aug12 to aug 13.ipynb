{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 3601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "essential-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicare",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "    'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    " 'Accuracy_threat_T1': 'T1Acc1t',\n",
    " 'Accuracy_NT_T1': 'T1Acc1n',\n",
    " 'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " 'Trait_T1': 'trait1',\n",
    " 'State_T1': 'state1',\n",
    "  'PCL_T1': 'PCL1',\n",
    " 'PCL_T4': 'PCL3'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['august12', 'august13'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016['Wave'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-diary",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "PCL_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire5_PCL.csv\"))                      \n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "intrusion_features_2016 = [\"q5.1\", \"q5.2\", \"q5.3\", \"q5.4\", \"q5.5\"]\n",
    "df_2009 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PCL_2016[intrusion_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(intrusion_features_2009, intrusion_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-money",
   "metadata": {},
   "source": [
    "## append PHQ9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire5_PHQ9.csv\"))\n",
    "PHQ9_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire4_PHQ9.csv\"))                      \n",
    "\n",
    "PHQ9_features_2009 = [\"T1q5.1\", \"T1q5.2\", \"T1q5.3\", \"T1q5.4\", \"T1q5.5\", \"T1q5.6\", \"T1q5.7\", \"T1q5.8\", \"T1q5.9\"]\n",
    "PHQ9_features_2016 = [\"q4.1\", \"q4.2\",\"q4.3\", \"q4.4\", \"q4.5\", \"q4.6\", \"q4.7\", \"q4.8\", \"q49\"]\n",
    "df_2009 = df_2009.merge(PHQ9_2009[PHQ9_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PHQ9_2016[PHQ9_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(PHQ9_features_2009, PHQ9_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-honolulu",
   "metadata": {},
   "source": [
    "## append trait featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trait_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire3_trait_anxiety_revised.csv\"))\n",
    "Trait_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire3_trait_anxiety.csv\"))                      \n",
    "\n",
    "Trait_features_2009 = [\"T1q3.1\", \"T1q3.2\", \"T1q3.3\", \"T1q3.4\", \"T1q3.5\", \"T1q3.6\", \"T1q3.7\", \"T1q3.8\", \"T1q3.9\", \"T1q3.10\", \"T1q3.11\", \"T1q3.12\", \"T1q3.13\", \"T1q3.14\", \"T1q3.15\", \"T1q3.16\", \"T1q3.17\", \"T1q3.18\", \"T1q3.19\", \"T1q3.20\"]\n",
    "Trait_features_2016 = [\"q3.1\", \"q3.2\", \"q3.3\", \"q3.4\", \"q3.5\", \"q3.6\", \"q3.7\", \"q3.8\", \"q3.9\", \"q3.10\", \"q3.11\", \"q3.12\", \"q3.13\", \"q3.14\", \"q3.15\", \"q3.16\", \"q3.17\", \"q3.18\", \"q3.19\", \"q3.20\"]\n",
    "df_2009 = df_2009.merge(Trait_2009[Trait_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(Trait_2016[Trait_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(Trait_features_2009, Trait_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-statistics",
   "metadata": {},
   "source": [
    "## append state featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire2_state_anxiety_revised.csv\"))\n",
    "State_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire2_state_anxiety.csv\"))                      \n",
    "\n",
    "State_features_2009 = [\"T1q2.1\", \"T1q2.2\", \"T1q2.3\", \"T1q2.4\", \"T1q2.5\", \"T1q2.6\", \"T1q2.7\", \"T1q2.8\", \"T1q2.9\", \"T1q2.10\", \"T1q2.11\", \"T1q2.12\", \"T1q2.13\", \"T1q2.14\", \"T1q2.15\", \"T1q2.16\", \"T1q2.17\", \"T1q2.18\", \"T1q2.19\", \"T1q2.20\"]\n",
    "State_features_2016 = [\"q2.1\", \"q2.2\", \"q2.3\", \"q2.4\", \"q2.5\", \"q2.6\", \"q2.7\", \"q2.8\", \"q2.9\", \"q2.10\", \"q2.11\", \"q2.12\", \"q2.13\", \"q2.14\", \"q2.15\", \"q2.16\", \"q2.17\", \"q2.18\", \"q2.19\", \"q2.20\"]\n",
    "df_2009 = df_2009.merge(State_2009[State_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(State_2016[State_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(State_features_2009, State_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-substance",
   "metadata": {},
   "source": [
    "## target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'PCL3'\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['PCL_T4'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "df_2009['PCL3'] = (df_2009['PCL3'] > 39).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-solomon",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009[target_feature].isna()]\n",
    "df_2016 = df_2016[~df_2016[target_feature].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-philadelphia",
   "metadata": {},
   "source": [
    "## 2009 data outer CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "functional-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(df_2009[X_features], df_2009[target_feature], test_size=0.25,\n",
    "                                        random_state=random_state, stratify=df_2009[target_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-bacteria",
   "metadata": {},
   "source": [
    "## parameters init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sufficient-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# class weight\n",
    "pos_sample = y.sum() \n",
    "all_samples = y.count()\n",
    "class_weights = all_samples/ pos_sample\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "   # ('RFE', RFE(CatBoostClassifier(verbose=0, random_state=random_state))),\n",
    "    ('classifier', CatBoostClassifier(verbose=0, random_state=random_state))])\n",
    "grid_params = [{\n",
    " #       'RFE__n_features_to_select': [15],\n",
    "        'classifier__class_weights':[[1, class_weights], [1, class_weights*2], [1, class_weights*0.5]],\n",
    "        'classifier__l2_leaf_reg': np.arange(1,10),\n",
    "        'classifier__depth': [4, 6, 8]#, 9]\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2016, y_2016 = df_2016[df_2016['Wave']=='august13'][X_features+['Intrusion_T1']], df_2016[df_2016['Wave']=='august13'][target_feature]\n",
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prostate-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6909019343229869, params = {'classifier__class_weights': [1, 6.361538461538461], 'classifier__depth': 6, 'classifier__l2_leaf_reg': 9}\n"
     ]
    }
   ],
   "source": [
    "x_2012, y_2012 = df_2016[df_2016['Wave']=='august12'][X_features+['Intrusion_T1']], df_2016[df_2016['Wave']=='august12'][target_feature]\n",
    "\n",
    "clf.fit(x_2012, y_2012.astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "endangered-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6316466552315609\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_2016)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_2016.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "endangered-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highschool_diploma 8.194818187848735\n",
      "ADHD 5.829346885576336\n",
      "T1Acc1t 10.259808263136863\n",
      "T1Acc1n 8.375020832495368\n",
      "T1bias 16.141649004582693\n",
      "phq1 8.241827811346214\n",
      "trait1 18.71452755375539\n",
      "state1 6.8744564014423695\n",
      "PCL1 11.281792458500677\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(X_features, clf.best_estimator_['classifier'].get_feature_importance()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-crisis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
