{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 3601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "essential-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "df_2016 = df_2016[(df_2016['Wave']=='august12')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-whale",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powered-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    "# 'Accuracy_threat_T1': 'T1Acc1t',\n",
    " #'Accuracy_NT_T1': 'T1Acc1n',\n",
    " #'Threat_Bias_T1': 'T1bias',\n",
    "  'PHQ_T1': 'phq1',\n",
    "#  #'Trait_T1': 'trait1',\n",
    " # 'State_T1': 'state1',\n",
    "   'PCL_T1': 'PCL1',\n",
    " 'PCL_T4': 'PCL3'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-apple",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "PCL_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire5_PCL.csv\"))                      \n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "intrusion_features_2016 = [\"q5.1\", \"q5.2\", \"q5.3\", \"q5.4\", \"q5.5\"]\n",
    "df_2009 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PCL_2016[intrusion_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(intrusion_features_2009, intrusion_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-thousand",
   "metadata": {},
   "source": [
    "## append PHQ9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire5_PHQ9.csv\"))\n",
    "PHQ9_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire4_PHQ9.csv\"))                      \n",
    "\n",
    "PHQ9_features_2009 = [\"T1q5.1\", \"T1q5.2\", \"T1q5.3\", \"T1q5.4\", \"T1q5.5\", \"T1q5.6\", \"T1q5.7\", \"T1q5.8\", \"T1q5.9\"]\n",
    "PHQ9_features_2016 = [\"q4.1\", \"q4.2\",\"q4.3\", \"q4.4\", \"q4.5\", \"q4.6\", \"q4.7\", \"q4.8\", \"q49\"]\n",
    "df_2009 = df_2009.merge(PHQ9_2009[PHQ9_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PHQ9_2016[PHQ9_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(PHQ9_features_2009, PHQ9_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-moses",
   "metadata": {},
   "source": [
    "## append trait featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trait_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire3_trait_anxiety_revised.csv\"))\n",
    "Trait_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire3_trait_anxiety.csv\"))                      \n",
    "\n",
    "Trait_features_2009 = [\"T1q3.1\", \"T1q3.2\", \"T1q3.3\", \"T1q3.4\", \"T1q3.5\", \"T1q3.6\", \"T1q3.7\", \"T1q3.8\", \"T1q3.9\", \"T1q3.10\", \"T1q3.11\", \"T1q3.12\", \"T1q3.13\", \"T1q3.14\", \"T1q3.15\", \"T1q3.16\", \"T1q3.17\", \"T1q3.18\", \"T1q3.19\", \"T1q3.20\"]\n",
    "Trait_features_2016 = [\"q3.1\", \"q3.2\", \"q3.3\", \"q3.4\", \"q3.5\", \"q3.6\", \"q3.7\", \"q3.8\", \"q3.9\", \"q3.10\", \"q3.11\", \"q3.12\", \"q3.13\", \"q3.14\", \"q3.15\", \"q3.16\", \"q3.17\", \"q3.18\", \"q3.19\", \"q3.20\"]\n",
    "df_2009 = df_2009.merge(Trait_2009[Trait_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(Trait_2016[Trait_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(Trait_features_2009, Trait_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-logic",
   "metadata": {},
   "source": [
    "## append state featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire2_state_anxiety_revised.csv\"))\n",
    "State_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire2_state_anxiety.csv\"))                      \n",
    "\n",
    "State_features_2009 = [\"T1q2.1\", \"T1q2.2\", \"T1q2.3\", \"T1q2.4\", \"T1q2.5\", \"T1q2.6\", \"T1q2.7\", \"T1q2.8\", \"T1q2.9\", \"T1q2.10\", \"T1q2.11\", \"T1q2.12\", \"T1q2.13\", \"T1q2.14\", \"T1q2.15\", \"T1q2.16\", \"T1q2.17\", \"T1q2.18\", \"T1q2.19\", \"T1q2.20\"]\n",
    "State_features_2016 = [\"q2.1\", \"q2.2\", \"q2.3\", \"q2.4\", \"q2.5\", \"q2.6\", \"q2.7\", \"q2.8\", \"q2.9\", \"q2.10\", \"q2.11\", \"q2.12\", \"q2.13\", \"q2.14\", \"q2.15\", \"q2.16\", \"q2.17\", \"q2.18\", \"q2.19\", \"q2.20\"]\n",
    "df_2009 = df_2009.merge(State_2009[State_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(State_2016[State_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(State_features_2009, State_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-volume",
   "metadata": {},
   "source": [
    "## target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'PCL3'\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['PCL_T4'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "df_2009['PCL3'] = (df_2009['PCL3'] > 39).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-aerospace",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009[target_feature].isna()]\n",
    "df_2016 = df_2016[~df_2016[target_feature].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-philadelphia",
   "metadata": {},
   "source": [
    "## 2009 data outer CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "functional-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(df_2009[X_features], df_2009[target_feature], test_size=0.25,\n",
    "                                        random_state=random_state, stratify=df_2009[target_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-injury",
   "metadata": {},
   "source": [
    "## parameters init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brazilian-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# class weight\n",
    "pos_sample = y.sum() \n",
    "all_samples = y.count()\n",
    "class_weights = all_samples/ pos_sample\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "   # ('RFE', RFE(CatBoostClassifier(verbose=0, random_state=random_state))),\n",
    "    ('classifier', CatBoostClassifier(verbose=0, random_state=random_state))])\n",
    "grid_params = [{\n",
    "        ##'RFE__n_features_to_select': [15, 5, 3, 8],\n",
    "       # 'classifier__class_weights':[[1, class_weights]],# [1, class_weights*2]],# [1, class_weights*0.5]],\n",
    "       # 'classifier__l2_leaf_reg': [100],# 250, 500],\n",
    "        'classifier__depth': [4]#, 9]\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-positive",
   "metadata": {},
   "source": [
    "## inner CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2016, y_2016 = df_2016[X_features], df_2016[target_feature]\n",
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prostate-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.697619669169443, params = {'classifier__depth': 4}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(df_2009[X_features], df_2009[target_feature].astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "endangered-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.716017316017316\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_2016)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_2016.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "heavy-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highschool_diploma 11.018780156042911\n",
      "ADHD 7.332183508612185\n",
      "phq1 38.71643341850334\n",
      "PCL1 42.93260291684157\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(X_features, clf.best_estimator_['classifier'].get_feature_importance()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
