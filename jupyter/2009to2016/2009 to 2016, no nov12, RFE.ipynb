{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "random_state = 36021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "active-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from fancyimpute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "essential-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "df_2016 = df_2016[~(df_2016['Wave']=='nov12')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-grove",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    "    'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    " 'Accuracy_threat_T1': 'T1Acc1t',\n",
    " 'Accuracy_NT_T1': 'T1Acc1n',\n",
    " 'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " 'Trait_T1': 'trait1',\n",
    " 'State_T1': 'state1',\n",
    "  'PCL_T1': 'PCL1',\n",
    " 'PCL_T4': 'PCL3'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-breakdown",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "literary-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "PCL_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire5_PCL.csv\"))                      \n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "intrusion_features_2016 = [\"q5.1\", \"q5.2\", \"q5.3\", \"q5.4\", \"q5.5\"]\n",
    "df_2009 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PCL_2016[intrusion_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(intrusion_features_2009, intrusion_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-inclusion",
   "metadata": {},
   "source": [
    "## append PHQ9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire5_PHQ9.csv\"))\n",
    "PHQ9_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire4_PHQ9.csv\"))                      \n",
    "\n",
    "PHQ9_features_2009 = [\"T1q5.1\", \"T1q5.2\", \"T1q5.3\", \"T1q5.4\", \"T1q5.5\", \"T1q5.6\", \"T1q5.7\", \"T1q5.8\", \"T1q5.9\"]\n",
    "PHQ9_features_2016 = [\"q4.1\", \"q4.2\",\"q4.3\", \"q4.4\", \"q4.5\", \"q4.6\", \"q4.7\", \"q4.8\", \"q49\"]\n",
    "df_2009 = df_2009.merge(PHQ9_2009[PHQ9_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PHQ9_2016[PHQ9_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(PHQ9_features_2009, PHQ9_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-somewhere",
   "metadata": {},
   "source": [
    "## append trait featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liked-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trait_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire3_trait_anxiety_revised.csv\"))\n",
    "Trait_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire3_trait_anxiety.csv\"))                      \n",
    "\n",
    "Trait_features_2009 = [\"T1q3.1\", \"T1q3.2\", \"T1q3.3\", \"T1q3.4\", \"T1q3.5\", \"T1q3.6\", \"T1q3.7\", \"T1q3.8\", \"T1q3.9\", \"T1q3.10\", \"T1q3.11\", \"T1q3.12\", \"T1q3.13\", \"T1q3.14\", \"T1q3.15\", \"T1q3.16\", \"T1q3.17\", \"T1q3.18\", \"T1q3.19\", \"T1q3.20\"]\n",
    "Trait_features_2016 = [\"q3.1\", \"q3.2\", \"q3.3\", \"q3.4\", \"q3.5\", \"q3.6\", \"q3.7\", \"q3.8\", \"q3.9\", \"q3.10\", \"q3.11\", \"q3.12\", \"q3.13\", \"q3.14\", \"q3.15\", \"q3.16\", \"q3.17\", \"q3.18\", \"q3.19\", \"q3.20\"]\n",
    "df_2009 = df_2009.merge(Trait_2009[Trait_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(Trait_2016[Trait_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(Trait_features_2009, Trait_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-concern",
   "metadata": {},
   "source": [
    "## append state featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proved-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire2_state_anxiety_revised.csv\"))\n",
    "State_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire2_state_anxiety.csv\"))                      \n",
    "\n",
    "State_features_2009 = [\"T1q2.1\", \"T1q2.2\", \"T1q2.3\", \"T1q2.4\", \"T1q2.5\", \"T1q2.6\", \"T1q2.7\", \"T1q2.8\", \"T1q2.9\", \"T1q2.10\", \"T1q2.11\", \"T1q2.12\", \"T1q2.13\", \"T1q2.14\", \"T1q2.15\", \"T1q2.16\", \"T1q2.17\", \"T1q2.18\", \"T1q2.19\", \"T1q2.20\"]\n",
    "State_features_2016 = [\"q2.1\", \"q2.2\", \"q2.3\", \"q2.4\", \"q2.5\", \"q2.6\", \"q2.7\", \"q2.8\", \"q2.9\", \"q2.10\", \"q2.11\", \"q2.12\", \"q2.13\", \"q2.14\", \"q2.15\", \"q2.16\", \"q2.17\", \"q2.18\", \"q2.19\", \"q2.20\"]\n",
    "df_2009 = df_2009.merge(State_2009[State_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(State_2016[State_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(State_features_2009, State_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-finger",
   "metadata": {},
   "source": [
    "## target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'PCL3'\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "massive-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['PCL_T4'] = (df_2016['PCL_T4'] > 40).astype(int)\n",
    "df_2009['PCL3'] = (df_2009['PCL3'] > 40).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-software",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009[target_feature].isna()]\n",
    "df_2016 = df_2016[~df_2016[target_feature].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-philadelphia",
   "metadata": {},
   "source": [
    "## 2009 data outer CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "functional-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(df_2009[X_features], df_2009[target_feature], test_size=0.25,\n",
    "                                        random_state=random_state, stratify=df_2009[target_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-detail",
   "metadata": {},
   "source": [
    "## parameters init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "horizontal-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "? IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "running-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# class weight\n",
    "pos_sample = y.sum() \n",
    "all_samples = y.count()\n",
    "class_weights = all_samples/ pos_sample\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('Mice',  IterativeImputer(random_state=random_state, max_iter=65)),\n",
    "    ('RFE', RFE(ExtraTreesClassifier(random_state=random_state))),\n",
    "    ('classifier', CatBoostClassifier(verbose=0, random_state=random_state))\n",
    "\n",
    "    ])\n",
    "grid_params = [{\n",
    "        'RFE__n_features_to_select': [15, 35, 55],\n",
    "        #'classifier__bagging_temperature': [1, 10, 50],#, 9]\n",
    "        #'classifier__learning_rate':[None, 0.01, 0.1],\n",
    "        'classifier__class_weights':[[1, class_weights]],# [1, class_weights*2]],# [1, class_weights*0.5]],\n",
    "        'classifier__l2_leaf_reg': [150, 3],# 250, 500],\n",
    "        #'classifier__depth': [4, 7]#, 9]\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-modern",
   "metadata": {},
   "source": [
    "## inner CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "registered-miller",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y,  random_state=random_state, test_size=0.2, stratify=y)\n",
    "## grid search\n",
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "handled-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6735252915441617, params = {'RFE__n_features_to_select': 55, 'classifier__class_weights': [1, 13.573770491803279], 'classifier__l2_leaf_reg': 150}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train.values.astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "likely-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.799512987012987\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_val)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_val.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-validity",
   "metadata": {},
   "source": [
    "## outer CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interracial-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6703796080887616, params = {'RFE__n_features_to_select': 55, 'classifier__class_weights': [1, 13.573770491803279], 'classifier__l2_leaf_reg': 3}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n",
    "clf.fit(x, y.values.astype(int), classifier__early_stopping_rounds = 15)\n",
    "\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unique-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.7109922178988327\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_test)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_test.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "accredited-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2016, y_2016 = df_2016[X_features], df_2016[target_feature]\n",
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "prostate-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "C:\\Users\\nogag\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:686: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6780405639538766, params = {'RFE__n_features_to_select': 35, 'classifier__class_weights': [1, 13.573770491803279], 'classifier__l2_leaf_reg': 150}\n"
     ]
    }
   ],
   "source": [
    "clf.fit(df_2009[X_features], df_2009[target_feature].astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "endangered-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.4901079895385134\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_2016)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_2016.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "heavy-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highschool_diploma 3.861605010719701\n",
      "ADHD 3.3598636410587335\n",
      "T1Acc1t 3.3481488204795333\n",
      "T1Acc1n 6.519837822341892\n",
      "T1bias 4.448840522602901\n",
      "phq1 1.9227397722132664\n",
      "trait1 3.062935294603366\n",
      "state1 9.731166664140055\n",
      "PCL1 1.6126299121046557\n",
      "q6.1_INTRU 2.1672486008953196\n",
      "q6.2_DREAM 1.9111880015127454\n",
      "q6.3_FLASH 1.8534408834285447\n",
      "q6.4_UPSET 1.4828224732678412\n",
      "q6.5_PHYS 2.9729834830131816\n",
      "T1q5.1 3.4354634386258605\n",
      "T1q5.2 3.6613550985585785\n",
      "T1q5.3 1.889573812313855\n",
      "T1q5.4 3.7427144356320756\n",
      "T1q5.5 3.4560774106603107\n",
      "T1q5.6 1.7260383621898596\n",
      "T1q5.7 2.8537370706839162\n",
      "T1q5.8 1.5123887633563853\n",
      "T1q5.9 1.900691651501232\n",
      "T1q3.1 2.800906408583409\n",
      "T1q3.2 2.0892137766339425\n",
      "T1q3.3 4.0404428289153635\n",
      "T1q3.4 3.367204329168988\n",
      "T1q3.5 1.8209417802936976\n",
      "T1q3.6 3.013473002746697\n",
      "T1q3.7 1.875279508638163\n",
      "T1q3.8 1.7375756499194293\n",
      "T1q3.9 0.8248161966384734\n",
      "T1q3.10 1.2730630332702617\n",
      "T1q3.11 3.2620430248245897\n",
      "T1q3.12 1.4615495144632098\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(x_train.columns, clf.best_estimator_['classifier'].get_feature_importance()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "useful-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1348    0\n",
       "1349    0\n",
       "1350    0\n",
       "1351    0\n",
       "1352    0\n",
       "Name: PCL3, Length: 1353, dtype: int32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2016.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "standing-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4901079895385134"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_2016.astype(int), y_pred_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
