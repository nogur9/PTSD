{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 3601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "essential-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2009 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2009'\n",
    "df_2009 = pd.read_excel(os.path.join(data_path_2009, \"PTSD.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2016 = r'C:\\Users\\nogag\\Documents\\birocracy\\PTSDClassifier\\PTSD\\Data\\2016'\n",
    "df_2016 = pd.read_csv(os.path.join(data_path_2016, \"IDF_ABM_16.2.15_wide.csv\"))\n",
    "\n",
    "\n",
    "df_2016 = df_2016[(df_2016['Wave']=='august12')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-findings",
   "metadata": {},
   "source": [
    "## features in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polished-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_2016_2009_features = {\n",
    " 'bagrut': 'highschool_diploma',\n",
    " 'ADHD': 'ADHD',\n",
    " #'Accuracy_threat_T1': 'T1Acc1t',\n",
    " #'Accuracy_NT_T1': 'T1Acc1n',\n",
    " #'Threat_Bias_T1': 'T1bias',\n",
    " 'PHQ_T1': 'phq1',\n",
    " #'Trait_T1': 'trait1',\n",
    " #'State_T1': 'state1',\n",
    "  #'PCL_T1': 'PCL1',\n",
    " 'PCL_T4': 'PCL3'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-examination",
   "metadata": {},
   "source": [
    "## append PCL intrusion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCL_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire_PCL1.csv\"))\n",
    "PCL_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire5_PCL.csv\"))                      \n",
    "\n",
    "intrusion_features_2009 = [\"q6.1_INTRU\", \"q6.2_DREAM\", \"q6.3_FLASH\", \"q6.4_UPSET\", \"q6.5_PHYS\"]\n",
    "intrusion_features_2016 = [\"q5.1\", \"q5.2\", \"q5.3\", \"q5.4\", \"q5.5\"]\n",
    "df_2009 = df_2009.merge(PCL_2009[intrusion_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PCL_2016[intrusion_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(intrusion_features_2009, intrusion_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-overall",
   "metadata": {},
   "source": [
    "## append PHQ9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHQ9_2009 = pd.read_csv(os.path.join(data_path_2009, \"questionnaire5_PHQ9.csv\"))\n",
    "PHQ9_2016 = pd.read_csv(os.path.join(data_path_2016, \"questionnaire4_PHQ9.csv\"))                      \n",
    "\n",
    "PHQ9_features_2009 = [\"T1q5.1\", \"T1q5.2\", \"T1q5.3\", \"T1q5.4\", \"T1q5.5\", \"T1q5.6\", \"T1q5.7\", \"T1q5.8\", \"T1q5.9\"]\n",
    "PHQ9_features_2016 = [\"q4.1\", \"q4.2\",\"q4.3\", \"q4.4\", \"q4.5\", \"q4.6\", \"q4.7\", \"q4.8\", \"q49\"]\n",
    "df_2009 = df_2009.merge(PHQ9_2009[PHQ9_features_2009 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "df_2016 = df_2016.merge(PHQ9_2016[PHQ9_features_2016 + [\"ID\"]], on=\"ID\", how='outer')\n",
    "\n",
    "for i, j in zip(PHQ9_features_2009, PHQ9_features_2016):\n",
    "    trans_2016_2009_features[j] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-switzerland",
   "metadata": {},
   "source": [
    "## target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'PCL3'\n",
    "X_features = [i for i in trans_2016_2009_features.values() if not i == target_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['PCL_T4'] = (df_2016['PCL_T4'] > 39).astype(int)\n",
    "df_2009['PCL3'] = (df_2009['PCL3'] > 39).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-illness",
   "metadata": {},
   "source": [
    "## adjust features from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016['bagrut'] = df_2016['bagrut'] == 'yes'\n",
    "df_2016['dyslexia'] = df_2016['dyslexia'] == 'yes'\n",
    "df_2016['ADHD'] = df_2016['ADHD'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "israeli-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_2016.rename(trans_2016_2009_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metallic-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009 = df_2009[~df_2009[target_feature].isna()]\n",
    "df_2016 = df_2016[~df_2016[target_feature].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-philadelphia",
   "metadata": {},
   "source": [
    "## 2009 data outer CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "functional-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(df_2009[X_features], df_2009[target_feature], test_size=0.25,\n",
    "                                        random_state=random_state, stratify=df_2009[target_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-destination",
   "metadata": {},
   "source": [
    "## parameters init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "periodic-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(6, random_state=random_state, shuffle=True)\n",
    "\n",
    "# class weight\n",
    "pos_sample = y.sum() \n",
    "all_samples = y.count()\n",
    "class_weights = all_samples/ pos_sample\n",
    "\n",
    "\n",
    "# pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    " #   ('RFE', RFE(CatBoostClassifier(verbose=0, random_state=random_state))),\n",
    "    ('classifier', CatBoostClassifier(verbose=0, random_state=random_state))])\n",
    "grid_params = [{\n",
    "  #      'RFE__n_features_to_select': [15, 5, 3, 8],\n",
    "       # 'classifier__class_weights':[[1, class_weights]],# [1, class_weights*2]],# [1, class_weights*0.5]],\n",
    "       # 'classifier__l2_leaf_reg': [100],# 250, 500],\n",
    "        'classifier__depth': [4]#, 9]\n",
    "        }]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seattle",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tracked-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2016, y_2016 = df_2016[X_features], df_2016[target_feature] *0 +1\n",
    "x_2009, y_2009 = df_2009[X_features], df_2009[target_feature] * 0\n",
    "\n",
    "X = pd.concat([x_2016, x_2009])\n",
    "Y = np.hstack([y_2016, y_2009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "armed-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, Y,  random_state=random_state, test_size=0.2, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prostate-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6952368068439497, params = {'classifier__depth': 4}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, grid_params, cv=cv, scoring='roc_auc')\n",
    "clf.fit(x_train, y_train.astype(int), classifier__early_stopping_rounds = 15)\n",
    "print(f\"roc_auc = {clf.best_score_}, params = {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "endangered-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.6707673453996983\n"
     ]
    }
   ],
   "source": [
    "y_pred_target = clf.best_estimator_.predict_proba(x_val)[:, 1]\n",
    "print(f\"roc_auc = {roc_auc_score(y_val.astype(int), y_pred_target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "heavy-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highschool_diploma 12.381828138410995\n",
      "ADHD 7.471420175524952\n",
      "phq1 80.14675168606405\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(X_features, clf.best_estimator_['classifier'].get_feature_importance()):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "useful-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "236    1\n",
       "237    1\n",
       "238    1\n",
       "239    1\n",
       "240    1\n",
       "Name: PCL3, Length: 241, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2016.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
